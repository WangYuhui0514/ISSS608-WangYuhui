{
  "hash": "b65713d53f6779bcaa5fd73aa8b29f5a",
  "result": {
    "markdown": "---\ntitle: \"Take Home Exercise 3: Learning Behavior Patterns Analysis\"\nauthor: \"Wang Yuhui\"\ndate: \"June 2, 2024\"\ndate-modified: \"last-modified\"\nexecute: \n  warning: false\n  freeze: true\n---\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"show the code\"}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(lubridate)\nlibrary(cluster)\nlibrary(factoextra)\nlibrary(fmsb)\nlibrary(reshape2)\nlibrary(networkD3)\n```\n:::\n\n\n# 1 Objective\n\nMine **personalized learning behavior patterns** based on **learners' characteristics**.\n\nDesign and present **learners' profiles** from various perspectives, including:\n\n**-peak answering hours,**\n\n**-preferred question types,**\n\n**-correct answering rates, etc.**\n\n# 2 Data Preparation\n\n## 2.1 Data Observation\n\nfirst, we merge all the submission record.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"show the code\"}\nfile1 <- \"data/Data_SubmitRecord/SubmitRecord-Class1.csv\"\nfile2 <- \"data/Data_SubmitRecord/SubmitRecord-Class2.csv\"\nfile3 <- \"data/Data_SubmitRecord/SubmitRecord-Class3.csv\"\nfile4 <- \"data/Data_SubmitRecord/SubmitRecord-Class4.csv\"\nfile5 <- \"data/Data_SubmitRecord/SubmitRecord-Class5.csv\"\nfile6 <- \"data/Data_SubmitRecord/SubmitRecord-Class6.csv\"\nfile7 <- \"data/Data_SubmitRecord/SubmitRecord-Class7.csv\"\nfile8 <- \"data/Data_SubmitRecord/SubmitRecord-Class8.csv\"\nfile9 <- \"data/Data_SubmitRecord/SubmitRecord-Class9.csv\"\nfile10 <- \"data/Data_SubmitRecord/SubmitRecord-Class10.csv\"\nfile11 <- \"data/Data_SubmitRecord/SubmitRecord-Class11.csv\"\nfile12 <- \"data/Data_SubmitRecord/SubmitRecord-Class12.csv\"\nfile13 <- \"data/Data_SubmitRecord/SubmitRecord-Class13.csv\"\nfile14 <- \"data/Data_SubmitRecord/SubmitRecord-Class14.csv\"\nfile15 <- \"data/Data_SubmitRecord/SubmitRecord-Class15.csv\"\n\n# 读取 CSV 文件\ndata1 <- read.csv(file1)\ndata2 <- read.csv(file2)\ndata3 <- read.csv(file3)\ndata4 <- read.csv(file4)\ndata5 <- read.csv(file5)\ndata6 <- read.csv(file6)\ndata7 <- read.csv(file7)\ndata8 <- read.csv(file8)\ndata9 <- read.csv(file9)\ndata10 <- read.csv(file10)\ndata11 <- read.csv(file11)\ndata12 <- read.csv(file12)\ndata13 <- read.csv(file13)\ndata14 <- read.csv(file14)\ndata15 <- read.csv(file15)\n\nsubmit_data <- bind_rows(data1, data2, data3, data4, data5, data6, data7, data8, data9, data10, data11, data12, data13, data14, data15,)\n\nhead(submit_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  index  class       time              state score\n1     0 Class1 1704209872 Absolutely_Correct     3\n2     1 Class1 1704209852 Absolutely_Correct     3\n3     2 Class1 1704209838 Absolutely_Correct     3\n4     3 Class1 1704208923 Absolutely_Correct     3\n5     4 Class1 1704208359 Absolutely_Correct     4\n6     5 Class1 1704208330             Error1     0\n                       title_ID                      method memory timeconsume\n1 Question_bumGRTJ0c8p4v5D6eHZa Method_Cj9Ya2R7fZd6xs1q5mNQ    320           3\n2 Question_62XbhBvJ8NUSnApgDL94 Method_gj1NLb4Jn7URf9K2kQPd    356           3\n3 Question_ZTbD7mxr2OUp8Fz6iNjy Method_5Q4KoXthUuYz3bvrTDFm    196           2\n4 Question_xqlJkmRaP0otZcX4fK3W Method_m8vwGkEZc3TSW2xqYUoR    308           2\n5 Question_FNg8X9v5zcbB1tQrxHR3 Method_Cj9Ya2R7fZd6xs1q5mNQ    320           3\n6 Question_FNg8X9v5zcbB1tQrxHR3 Method_gj1NLb4Jn7URf9K2kQPd      0           5\n            student_ID\n1 8b6d1125760bd3939b6e\n2 8b6d1125760bd3939b6e\n3 8b6d1125760bd3939b6e\n4 63eef37311aaac915a45\n5 5d89810b20079366fcc2\n6 5d89810b20079366fcc2\n```\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"show the code\"}\nwrite.csv(submit_data, \"data/submit_data.csv\", row.names = FALSE)\n```\n:::\n\n\nNow we have 3 data sets in total, which are:\n\n-   Student information data\n\n-   Question title information\n\n-   Submission record information\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nstu_info <- read.csv('data/Data_Studentinfo.csv')\ntit_info <- read.csv('data/Data_Titleinfo.csv')\nsub_info <- read.csv('data/submit_data.csv')\nsummary(stu_info)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     index         student_ID            sex                 age       \n Min.   :   1.0   Length:1364        Length:1364        Min.   :18.00  \n 1st Qu.: 341.8   Class :character   Class :character   1st Qu.:19.00  \n Median : 682.5   Mode  :character   Mode  :character   Median :21.00  \n Mean   : 682.5                                         Mean   :21.05  \n 3rd Qu.:1023.2                                         3rd Qu.:23.00  \n Max.   :1364.0                                         Max.   :24.00  \n    major          \n Length:1364       \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n```\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nsummary(tit_info)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     index         title_ID             score        knowledge        \n Min.   : 1.00   Length:44          Min.   :1.000   Length:44         \n 1st Qu.:11.75   Class :character   1st Qu.:2.750   Class :character  \n Median :22.50   Mode  :character   Median :3.000   Mode  :character  \n Mean   :22.50                      Mean   :2.636                     \n 3rd Qu.:33.25                      3rd Qu.:3.000                     \n Max.   :44.00                      Max.   :4.000                     \n sub_knowledge     \n Length:44         \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n```\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nsummary(sub_info)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     index          class                time              state          \n Min.   :    0   Length:232818      Min.   :1.693e+09   Length:232818     \n 1st Qu.: 3880   Class :character   1st Qu.:1.697e+09   Class :character  \n Median : 7760   Mode  :character   Median :1.699e+09   Mode  :character  \n Mean   : 7967                      Mean   :1.699e+09                     \n 3rd Qu.:11640                      3rd Qu.:1.701e+09                     \n Max.   :20201                      Max.   :1.706e+09                     \n     score          title_ID            method              memory       \n Min.   :0.0000   Length:232818      Length:232818      Min.   :    0.0  \n 1st Qu.:0.0000   Class :character   Class :character   1st Qu.:  188.0  \n Median :0.0000   Mode  :character   Mode  :character   Median :  324.0  \n Mean   :0.8991                                         Mean   :  347.3  \n 3rd Qu.:2.0000                                         3rd Qu.:  356.0  \n Max.   :4.0000                                         Max.   :65536.0  \n timeconsume         student_ID       \n Length:232818      Length:232818     \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n                                      \n                                      \n                                      \n```\n:::\n:::\n\n\n## 2.2 Data Clean\n\n### 2.2.1 Missing Value\n\nFirst, we check if there is missing value in these 3 data sets.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"show the code\"}\nmissing_values1 <- colSums(is.na(stu_info))\nprint(missing_values1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     index student_ID        sex        age      major \n         0          0          0          0          0 \n```\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"show the code\"}\nmissing_values2 <- colSums(is.na(tit_info))\nprint(missing_values2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        index      title_ID         score     knowledge sub_knowledge \n            0             0             0             0             0 \n```\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"show the code\"}\nmissing_values3 <- colSums(is.na(sub_info))\nprint(missing_values3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      index       class        time       state       score    title_ID \n          0           0           0           0           0           0 \n     method      memory timeconsume  student_ID \n          0           0           0           0 \n```\n:::\n:::\n\n\n### 2.2.2 Outliers\n\nThere is no missing value in all 3 data sets. Now we see if there are outliers. :\n\n::: panel-tabset\n## state\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"show the code\"}\nunique_state <- unique(sub_info$state)\nprint(unique_state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Absolutely_Correct\" \"Error1\"             \"Absolutely_Error\"  \n [4] \"Error6\"             \"Error4\"             \"Partially_Correct\" \n [7] \"Error2\"             \"Error3\"             \"Error5\"            \n[10] \"Error7\"             \"Error8\"             \"Error9\"            \n[13] \"�������\"           \n```\n:::\n:::\n\n\n## class\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"show the code\"}\nunique_class <- unique(sub_info$class)\nprint(unique_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Class1\"  \"class\"   \"Class2\"  \"Class3\"  \"Class4\"  \"Class5\"  \"Class6\" \n [8] \"Class7\"  \"Class8\"  \"Class9\"  \"Class10\" \"Class11\" \"Class12\" \"Class13\"\n[15] \"Class14\" \"Class15\"\n```\n:::\n:::\n\n\n## time consume\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"show the code\"}\nunique_timeconsume <- unique(sub_info$timeconsume) \nprint(unique_timeconsume)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] \"3\"   \"2\"   \"5\"   \"4\"   \"1\"   \"9\"   \"6\"   \"--\"  \"18\"  \"61\"  \"7\"   \"59\" \n [13] \"10\"  \"8\"   \"12\"  \"13\"  \"16\"  \"15\"  \"183\" \"68\"  \"314\" \"64\"  \"60\"  \"11\" \n [25] \"96\"  \"94\"  \"58\"  \"67\"  \"54\"  \"17\"  \"122\" \"19\"  \"126\" \"14\"  \"91\"  \"50\" \n [37] \"21\"  \"40\"  \"23\"  \"20\"  \"80\"  \"31\"  \"118\" \"25\"  \"26\"  \"29\"  \"28\"  \"27\" \n [49] \"24\"  \"65\"  \"135\" \"63\"  \"103\" \"114\" \"258\" \"254\" \"85\"  \"66\"  \"69\"  \"90\" \n [61] \"132\" \"173\" \"48\"  \"34\"  \"272\" \"38\"  \"113\" \"116\" \"32\"  \"76\"  \"22\"  \"190\"\n [73] \"187\" \"73\"  \"215\" \"123\" \"246\" \"146\" \"57\"  \"89\"  \"88\"  \"30\"  \"245\" \"75\" \n [85] \"285\" \"70\"  \"400\" \"205\" \"36\"  \"164\" \"163\" \"162\" \"165\" \"266\" \"62\"  \"172\"\n [97] \"143\" \"184\" \"42\"  \"377\" \"160\" \"33\"  \"35\"  \"159\" \"182\" \"41\"  \"52\"  \"74\" \n[109] \"72\"  \"46\"  \"264\" \"81\"  \"153\" \"83\"  \"82\"  \"39\"  \"37\"  \"56\"  \"-\"   \"115\"\n[121] \"55\"  \"286\" \"275\" \"331\" \"280\" \"274\" \"269\" \"288\" \"271\" \"136\" \"117\" \"276\"\n[133] \"277\" \"356\" \"79\"  \"147\" \"44\"  \"350\" \"394\" \"45\"  \"315\" \"321\" \"302\" \"152\"\n[145] \"309\" \"47\"  \"53\"  \"51\"  \"307\" \"201\" \"43\"  \"109\" \"326\" \"49\"  \"77\"  \"71\" \n[157] \"385\" \"78\"  \"220\" \"217\" \"86\"  \"134\" \"84\"  \"106\" \"166\" \"124\" \"373\" \"289\"\n```\n:::\n:::\n\n:::\n\nFor outliers \"�������\" , simply remove it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvalid_states <- c(\"Absolutely_Correct\", \"Absolutely_Error\", \"Error1\", \"Error2\", \"Error3\", \"Error4\", \"Error6\", \"Error7\", \"Error8\", \"Error9\", \"Partially_Correct\")\n\n# 过滤数据，只保留 state 列中包含指定值的行\nsub_info <- sub_info %>%\n  filter(state %in% valid_states)\nunique(sub_info$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Absolutely_Correct\" \"Error1\"             \"Absolutely_Error\"  \n [4] \"Error6\"             \"Error4\"             \"Partially_Correct\" \n [7] \"Error2\"             \"Error3\"             \"Error7\"            \n[10] \"Error8\"             \"Error9\"            \n```\n:::\n:::\n\n\nFor outliers \"class\" , replace with the highest frequency of the corresponding student_ID.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreplace_class <- function(df) {\n  df$class <- as.character(df$class)\n  \n  class_indices <- which(df$class == 'class')\n  \n  for (index in class_indices) {\n    student_id <- df$student_ID[index]\n    student_classes <- df$class[df$student_ID == student_id & df$class != 'class']\n    class_counts <- table(student_classes)\n    \n    if (length(class_counts) > 0) {\n      most_common_class <- names(which.max(class_counts))\n      df$class[index] <- most_common_class\n    }\n  }\n  \n  return(df)\n}\nsub_info <- replace_class(sub_info)\nunique(sub_info$class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Class1\"  \"Class2\"  \"Class3\"  \"Class4\"  \"Class5\"  \"Class6\"  \"Class7\" \n [8] \"Class8\"  \"Class9\"  \"Class10\" \"Class11\" \"Class12\" \"Class13\" \"Class14\"\n[15] \"Class15\"\n```\n:::\n:::\n\n\nFor outliers '-' and '--', remove the corresponding rows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsub_info <- sub_info %>%\n  filter(!(timeconsume %in% c('-', '--')))\nunique(sub_info$timeconsume)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] \"3\"   \"2\"   \"5\"   \"4\"   \"1\"   \"9\"   \"6\"   \"18\"  \"61\"  \"7\"   \"59\"  \"10\" \n [13] \"8\"   \"12\"  \"13\"  \"16\"  \"15\"  \"183\" \"68\"  \"314\" \"64\"  \"60\"  \"11\"  \"96\" \n [25] \"94\"  \"58\"  \"67\"  \"54\"  \"17\"  \"122\" \"19\"  \"126\" \"14\"  \"91\"  \"50\"  \"21\" \n [37] \"40\"  \"23\"  \"20\"  \"80\"  \"31\"  \"118\" \"25\"  \"26\"  \"29\"  \"28\"  \"27\"  \"24\" \n [49] \"65\"  \"135\" \"63\"  \"103\" \"114\" \"258\" \"254\" \"85\"  \"66\"  \"69\"  \"90\"  \"132\"\n [61] \"173\" \"48\"  \"34\"  \"272\" \"38\"  \"113\" \"116\" \"32\"  \"76\"  \"22\"  \"190\" \"187\"\n [73] \"73\"  \"215\" \"123\" \"246\" \"146\" \"57\"  \"89\"  \"88\"  \"30\"  \"245\" \"75\"  \"285\"\n [85] \"70\"  \"400\" \"205\" \"36\"  \"164\" \"163\" \"162\" \"165\" \"266\" \"62\"  \"172\" \"143\"\n [97] \"184\" \"42\"  \"377\" \"160\" \"33\"  \"35\"  \"159\" \"182\" \"41\"  \"52\"  \"74\"  \"72\" \n[109] \"46\"  \"264\" \"81\"  \"153\" \"83\"  \"82\"  \"39\"  \"37\"  \"56\"  \"115\" \"55\"  \"286\"\n[121] \"275\" \"331\" \"280\" \"274\" \"269\" \"288\" \"271\" \"136\" \"117\" \"276\" \"277\" \"79\" \n[133] \"147\" \"44\"  \"350\" \"394\" \"45\"  \"315\" \"321\" \"302\" \"152\" \"47\"  \"53\"  \"51\" \n[145] \"307\" \"201\" \"43\"  \"109\" \"326\" \"49\"  \"77\"  \"71\"  \"385\" \"78\"  \"220\" \"217\"\n[157] \"86\"  \"134\" \"84\"  \"106\" \"166\" \"124\" \"373\" \"289\"\n```\n:::\n:::\n\n\nSave the dataset and name it 'sub_info.csv'\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.csv(sub_info, 'data/sub_info.csv', row.names = FALSE)\nhead(sub_info)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  index  class       time              state score\n1     0 Class1 1704209872 Absolutely_Correct     3\n2     1 Class1 1704209852 Absolutely_Correct     3\n3     2 Class1 1704209838 Absolutely_Correct     3\n4     3 Class1 1704208923 Absolutely_Correct     3\n5     4 Class1 1704208359 Absolutely_Correct     4\n6     5 Class1 1704208330             Error1     0\n                       title_ID                      method memory timeconsume\n1 Question_bumGRTJ0c8p4v5D6eHZa Method_Cj9Ya2R7fZd6xs1q5mNQ    320           3\n2 Question_62XbhBvJ8NUSnApgDL94 Method_gj1NLb4Jn7URf9K2kQPd    356           3\n3 Question_ZTbD7mxr2OUp8Fz6iNjy Method_5Q4KoXthUuYz3bvrTDFm    196           2\n4 Question_xqlJkmRaP0otZcX4fK3W Method_m8vwGkEZc3TSW2xqYUoR    308           2\n5 Question_FNg8X9v5zcbB1tQrxHR3 Method_Cj9Ya2R7fZd6xs1q5mNQ    320           3\n6 Question_FNg8X9v5zcbB1tQrxHR3 Method_gj1NLb4Jn7URf9K2kQPd      0           5\n            student_ID\n1 8b6d1125760bd3939b6e\n2 8b6d1125760bd3939b6e\n3 8b6d1125760bd3939b6e\n4 63eef37311aaac915a45\n5 5d89810b20079366fcc2\n6 5d89810b20079366fcc2\n```\n:::\n:::\n\n\n### 2.2.3 Convert datetime\n\nThe time span is from August 31, 2023 to January 25, 2024, a total of 148 days. However, the content in column 'time' is actually in seconds. So we need to convert to datetime.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsub_info <- sub_info %>%\n  mutate(day = wday(as.POSIXct(time, origin = \"1970-01-01\", tz = \"UTC\"), week_start = 1))\nunique(sub_info$day)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2 1 6 5 4 7 3\n```\n:::\n:::\n\n\n### 2.2.4 Match the unique title_ID with unique knowledge\n\nFrom the code below we can see some titles match multiple knowledge\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle_knowledge_check <- tit_info %>%\n  group_by(title_ID) %>%\n  summarise(knowledge_count = n_distinct(knowledge)) %>%\n  filter(knowledge_count > 1)\n\nprint(title_knowledge_check)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 2\n  title_ID                      knowledge_count\n  <chr>                                   <int>\n1 Question_QRm48lXxzdP7Tn1WgNOf               2\n2 Question_lU2wvHSZq7m43xiVroBc               2\n3 Question_oCjnFLbIs4Uxwek9rBpu               2\n4 Question_pVKXjZn0BkSwYcsa7C31               2\n5 Question_x2Fy7rZ3SwYl9jMQkpOD               2\n```\n:::\n:::\n\n\nSince we don't know when the students submit the questions, which knowledge they actually focus on, so we use the probability to match the knowledge.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle_knowledge_count <- tit_info %>%\n  group_by(title_ID) %>%\n  summarise(knowledge_list = list(unique(knowledge))) %>%\n  mutate(knowledge = sapply(knowledge_list, function(x) ifelse(length(x) > 0, x[1], NA)),\n         knowledge1 = sapply(knowledge_list, function(x) ifelse(length(x) > 1, x[2], NA))) %>%\n  select(-knowledge_list)\n\n# 合并知识信息到sub_info\nset.seed(123) # 确保结果可重复\nsub_info <- sub_info %>%\n  left_join(title_knowledge_count, by = \"title_ID\") %>%\n  rowwise() %>%\n  mutate(knowledge = ifelse(!is.na(knowledge1), \n                            sample(c(knowledge, knowledge1), 1), \n                            knowledge)) %>%\n  ungroup() %>%\n  select(-knowledge1)\n\n# 查看处理后的数据框前几行\nhead(sub_info)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 12\n  index class     time state score title_ID method memory timeconsume student_ID\n  <int> <chr>    <int> <chr> <int> <chr>    <chr>   <int> <chr>       <chr>     \n1     0 Class1  1.70e9 Abso…     3 Questio… Metho…    320 3           8b6d11257…\n2     1 Class1  1.70e9 Abso…     3 Questio… Metho…    356 3           8b6d11257…\n3     2 Class1  1.70e9 Abso…     3 Questio… Metho…    196 2           8b6d11257…\n4     3 Class1  1.70e9 Abso…     3 Questio… Metho…    308 2           63eef3731…\n5     4 Class1  1.70e9 Abso…     4 Questio… Metho…    320 3           5d89810b2…\n6     5 Class1  1.70e9 Erro…     0 Questio… Metho…      0 5           5d89810b2…\n# ℹ 2 more variables: day <dbl>, knowledge <chr>\n```\n:::\n:::\n\n\nFinally, we need to calculate the average answering correct rate and average consuming time for each student.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsub_info <- sub_info %>%\n  left_join(tit_info %>% select(title_ID, score), by = \"title_ID\")\nsub_info <- sub_info %>%\n  mutate(rate = score.x / score.y) %>%\n  select(-score.x, -score.y)\n\nhead(sub_info)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 12\n  index class     time state title_ID method memory timeconsume student_ID   day\n  <int> <chr>    <int> <chr> <chr>    <chr>   <int> <chr>       <chr>      <dbl>\n1     0 Class1  1.70e9 Abso… Questio… Metho…    320 3           8b6d11257…     2\n2     1 Class1  1.70e9 Abso… Questio… Metho…    356 3           8b6d11257…     2\n3     2 Class1  1.70e9 Abso… Questio… Metho…    196 2           8b6d11257…     2\n4     3 Class1  1.70e9 Abso… Questio… Metho…    308 2           63eef3731…     2\n5     4 Class1  1.70e9 Abso… Questio… Metho…    320 3           5d89810b2…     2\n6     5 Class1  1.70e9 Erro… Questio… Metho…      0 5           5d89810b2…     2\n# ℹ 2 more variables: knowledge <chr>, rate <dbl>\n```\n:::\n\n```{.r .cell-code}\nwrite.csv(sub_info,'data/sub_info.csv',row.names = FALSE)\n```\n:::\n\n\n### 2.2.5 Final data\n\nNow we merged with student information and rearrange the column for the further analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 计算每个学生的平均rate\navg_rate <- sub_info %>%\n  group_by(student_ID) %>%\n  summarise(average_rate = mean(rate, na.rm = TRUE))\n\n# 计算每个学生每种knowledge的百分比\nknowledge_percentage <- sub_info %>%\n  group_by(student_ID, knowledge) %>%\n  summarise(counts = n()) %>%\n  ungroup() %>%\n  group_by(student_ID) %>%\n  mutate(total_counts = sum(counts),\n         percentage = counts / total_counts) %>%\n  select(student_ID, knowledge, percentage) %>%\n  spread(key = knowledge, value = percentage, fill = 0)\n\n# 合并学生信息和计算结果\nfinal_data <- stu_info %>%\n  select(-index) %>%\n  left_join(avg_rate, by = \"student_ID\") %>%\n  left_join(sub_info %>% select(student_ID, day) %>% distinct(), by = \"student_ID\") %>%\n  left_join(knowledge_percentage, by = \"student_ID\")\n\n# 查看结果\nhead(final_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            student_ID    sex age  major average_rate day      b3C9s      g7R2j\n1 8b6d1125760bd3939b6e female  24 J23517    0.5187266   2 0.07865169 0.06741573\n2 8b6d1125760bd3939b6e female  24 J23517    0.5187266   3 0.07865169 0.06741573\n3 8b6d1125760bd3939b6e female  24 J23517    0.5187266   4 0.07865169 0.06741573\n4 63eef37311aaac915a45 female  21 J87654    0.1597715   2 0.01654846 0.05437352\n5 63eef37311aaac915a45 female  21 J87654    0.1597715   7 0.01654846 0.05437352\n6 63eef37311aaac915a45 female  21 J87654    0.1597715   4 0.01654846 0.05437352\n       k4W1c     m3D1v      r8S3g      s8Y2f     t5V9e     y9W5d\n1 0.02247191 0.2247191 0.32584270 0.02247191 0.1011236 0.1573034\n2 0.02247191 0.2247191 0.32584270 0.02247191 0.1011236 0.1573034\n3 0.02247191 0.2247191 0.32584270 0.02247191 0.1011236 0.1573034\n4 0.00000000 0.4018913 0.07801418 0.05673759 0.1229314 0.2695035\n5 0.00000000 0.4018913 0.07801418 0.05673759 0.1229314 0.2695035\n6 0.00000000 0.4018913 0.07801418 0.05673759 0.1229314 0.2695035\n```\n:::\n\n```{.r .cell-code}\nwrite.csv(final_data,'data/final_data.csv')\n```\n:::\n\n\n# 3 Clustering Analysis\n\n::: panel-tabset\n## code\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncluster_data <- final_data %>%\n  select(b3C9s, g7R2j, k4W1c, m3D1v, r8S3g, s8Y2f, t5V9e, y9W5d)\ncluster_data[is.na(cluster_data)] <- 0\ncluster_data_scaled <- scale(cluster_data)\n\n# define the number of clusters\nwss <- (nrow(cluster_data_scaled)-1)*sum(apply(cluster_data_scaled, 2, var))\nfor (i in 2:15) wss[i] <- sum(kmeans(cluster_data_scaled, centers=i)$tot.withinss)\n\n# elbow plot\nplot(1:15, wss, type=\"b\", xlab=\"Number of Clusters\", ylab=\"Within groups sum of squares\")\n\nset.seed(123)\nkmeans_result <- kmeans(cluster_data_scaled, centers=3, nstart=20)\n\nfinal_data <- final_data %>%\n  mutate(cluster = kmeans_result$cluster)\nprint(final_data)\n\ncluster_means <- final_data %>%\n  group_by(cluster) %>%\n  summarise(across(c(b3C9s, g7R2j, k4W1c, m3D1v, r8S3g, s8Y2f, t5V9e, y9W5d), mean, na.rm = TRUE))\nprint(cluster_means)\n\n# PCA scatter plot\npca <- prcomp(cluster_data_scaled)\npca_data <- data.frame(pca$x[, 1:2], cluster=as.factor(final_data$cluster))\n\nggplot(pca_data, aes(x = PC1, y = PC2, color = cluster)) + \n  geom_point() + \n  labs(title=\"K-means Clustering\", x=\"Principal Component 1\", y=\"Principal Component 2\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# 排除第一列计算最大值和最小值\nmax_values <- apply(cluster_means[, -1], 2, max)\nmin_values <- apply(cluster_means[, -1], 2, min)\n\n# 将最大值行、最小值行和聚类均值数据结合起来\nradar_data <- rbind(max_values, min_values, cluster_means[, -1])\n\n# 查看准备好的数据\nprint(radar_data)\n\n# 生成雷达图\ncolors_border <- c(\"blue\", \"green\", \"red\", \"orange\", \"purple\")\n\n# 生成雷达图\nradarchart(radar_data, axistype = 1,\n           pcol = colors_border, plwd = 2, plty = 1,\n           cglcol = \"grey\", cglty = 1, cglwd = 0.8,\n           vlcex = 0.8, title = \"Cluster Comparison Radar Chart\")\n\n# 添加图例\nlegend(x = \"topright\", legend = rownames(cluster_means), bty = \"n\",\n       pch = 20, col = colors_border, text.col = \"grey\", cex = 1.2, pt.cex = 3)\n```\n:::\n\n\n## elbow plot\n\n![](images/clipboard-3716576842.png)\n\n## PCA scatter plot\n\n![](images/clipboard-2838082180.png)\n\n## radar plot\n\n![](images/clipboard-1014584142.png)\n:::\n\n# 4 Conclusions\n\n## **Radar Chart Analysis**\n\nThe radar chart shows the comparison of knowledge distribution across three clusters. Here are the key observations: 1. Cluster 1 (Blue) • Exhibits a balanced performance across most knowledge areas, with relatively high percentages in y9W5d, g7R2j, and t5V9e. • It shows the highest values in several knowledge areas, indicating a well-rounded skill set among the students in this cluster.\n\n2.  Cluster 2 (Green)\n\n    • Shows a distinctive peak in r8S3g, suggesting that students in this cluster excel particularly in this knowledge area.\n\n    • Has lower percentages in areas like t5V9e and y9W5d compared to the other clusters.\n\n3.  Cluster 3 (Red)\n\n    • Dominates in m3D1v and k4W1c, indicating a specialized skill set focused on these areas.\n\n    • Displays lower values in other knowledge areas such as g7R2j and b3C9s.\n\nOverall, the radar chart indicates that each cluster has distinct strengths and weaknesses across different knowledge areas.\n\n## **PCA Scatter Plot Analysis**\n\nThe PCA scatter plot visualizes the distribution of students based on their principal components, colored by their assigned clusters:\n\n1.  Cluster Separation\n\n    • The three clusters are well-separated in the PCA space, indicating that the clustering algorithm effectively distinguished between different student groups.\n\n2.  Cluster Characteristics\n\n    • The separation suggests that students within each cluster share similar characteristics and knowledge distributions.\n\n    • The spread of points within each cluster implies some degree of variability, with Cluster 2 appearing to be the most dispersed.\n\n## **Summary**\n\nThe combined analysis of the radar chart and PCA scatter plot indicates that the clustering algorithm successfully identified three distinct groups of students with unique knowledge profiles. Cluster 1 has a balanced and well-rounded skill set, Cluster 2 is specialized in specific areas, and Cluster 3 shows a different specialization pattern. The clear separation in the PCA plot further supports the validity of these clusters.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}