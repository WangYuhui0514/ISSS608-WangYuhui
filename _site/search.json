[
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class ex 1",
    "section": "",
    "text": "In the code chunk below, p_load() of pacman package is used to load tidyverse family of package.\n\npacman::p_load(tidyverse, ggplot2)\n\n\nrealis &lt;- read_csv(\"data/realis2019.csv\")\n\n\nggplot(data=realis, aes(x = `Unit Price ($ psm)`)) +\n  geom_histogram(binwidth = 300)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "title": "In-class ex 1",
    "section": "",
    "text": "In the code chunk below, p_load() of pacman package is used to load tidyverse family of package.\n\npacman::p_load(tidyverse, ggplot2)\n\n\nrealis &lt;- read_csv(\"data/realis2019.csv\")\n\n\nggplot(data=realis, aes(x = `Unit Price ($ psm)`)) +\n  geom_histogram(binwidth = 300)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "pacman::p_load(tidyverse, ggstatsplot)\n\n\nexam &lt;- read_csv('data/Exam_data.csv')\n\n\nset.seed(1234)\n\np &lt;- gghistostats(\n      data = exam,\n      x = ENGLISH,\n      type = \"parametric\",\n      test.value = 60,\n      bin.args = list(color = 'black',\n                  xlab = \"English scores\")\n)\np\n\n\n\n\n\nextract_stats(p)\n\n$subtitle_data\n# A tibble: 1 × 15\n     mu statistic df.error  p.value method            alternative effectsize\n  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;       &lt;chr&gt;     \n1    60      8.77      321 1.04e-16 One Sample t-test two.sided   Hedges' g \n  estimate conf.level conf.low conf.high conf.method conf.distribution n.obs\n     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;int&gt;\n1    0.488       0.95    0.372     0.603 ncp         t                   322\n  expression\n  &lt;list&gt;    \n1 &lt;language&gt;\n\n$caption_data\n# A tibble: 1 × 16\n  term       effectsize      estimate conf.level conf.low conf.high    pd\n  &lt;chr&gt;      &lt;chr&gt;              &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 Difference Bayesian t-test     7.16       0.95     5.54      8.75     1\n  prior.distribution prior.location prior.scale    bf10 method         \n  &lt;chr&gt;                       &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          \n1 cauchy                          0       0.707 4.54e13 Bayesian t-test\n  conf.method log_e_bf10 n.obs expression\n  &lt;chr&gt;            &lt;dbl&gt; &lt;int&gt; &lt;list&gt;    \n1 ETI               31.4   322 &lt;language&gt;\n\n$pairwise_comparisons_data\nNULL\n\n$descriptive_data\nNULL\n\n$one_sample_data\nNULL\n\n$tidy_data\nNULL\n\n$glance_data\nNULL\n\n\n\nexam_long &lt;- exam %&gt;%\n  pivot_longer(\n    cols = ENGLISH:SCIENCE,\n    names_to = 'SUBJECT',\n    values_to = 'SCORES')%&gt;%\n  filter(CLASS == \"3A\")\n\n\nggwithinstats(\n  data = filter(exam_long,\n                SUBJECT %in%\n                  c(\"MATHS\", \"SCIENCE\")),\n  x = SUBJECT,\n  y = SCORES,\n  type = \"p\"\n)\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = TRUE,\n  label.var = ID,\n  label.expression = ENGLISH &gt;90 & MATHS &gt;90,\n)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-observation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-observation",
    "title": "Take Home Exercise 3: Learning Behavior Patterns Analysis",
    "section": "2.1 Data Observation",
    "text": "2.1 Data Observation\nfirst, we merge all the submission record.\n\n\nshow the code\nfile1 &lt;- \"data/Data_SubmitRecord/SubmitRecord-Class1.csv\"\nfile2 &lt;- \"data/Data_SubmitRecord/SubmitRecord-Class2.csv\"\nfile3 &lt;- \"data/Data_SubmitRecord/SubmitRecord-Class3.csv\"\nfile4 &lt;- \"data/Data_SubmitRecord/SubmitRecord-Class4.csv\"\nfile5 &lt;- \"data/Data_SubmitRecord/SubmitRecord-Class5.csv\"\nfile6 &lt;- \"data/Data_SubmitRecord/SubmitRecord-Class6.csv\"\nfile7 &lt;- \"data/Data_SubmitRecord/SubmitRecord-Class7.csv\"\nfile8 &lt;- \"data/Data_SubmitRecord/SubmitRecord-Class8.csv\"\nfile9 &lt;- \"data/Data_SubmitRecord/SubmitRecord-Class9.csv\"\nfile10 &lt;- \"data/Data_SubmitRecord/SubmitRecord-Class10.csv\"\nfile11 &lt;- \"data/Data_SubmitRecord/SubmitRecord-Class11.csv\"\nfile12 &lt;- \"data/Data_SubmitRecord/SubmitRecord-Class12.csv\"\nfile13 &lt;- \"data/Data_SubmitRecord/SubmitRecord-Class13.csv\"\nfile14 &lt;- \"data/Data_SubmitRecord/SubmitRecord-Class14.csv\"\nfile15 &lt;- \"data/Data_SubmitRecord/SubmitRecord-Class15.csv\"\n\n# 读取 CSV 文件\ndata1 &lt;- read.csv(file1)\ndata2 &lt;- read.csv(file2)\ndata3 &lt;- read.csv(file3)\ndata4 &lt;- read.csv(file4)\ndata5 &lt;- read.csv(file5)\ndata6 &lt;- read.csv(file6)\ndata7 &lt;- read.csv(file7)\ndata8 &lt;- read.csv(file8)\ndata9 &lt;- read.csv(file9)\ndata10 &lt;- read.csv(file10)\ndata11 &lt;- read.csv(file11)\ndata12 &lt;- read.csv(file12)\ndata13 &lt;- read.csv(file13)\ndata14 &lt;- read.csv(file14)\ndata15 &lt;- read.csv(file15)\n\nsubmit_data &lt;- bind_rows(data1, data2, data3, data4, data5, data6, data7, data8, data9, data10, data11, data12, data13, data14, data15,)\n\nhead(submit_data)\n\n\n  index  class       time              state score\n1     0 Class1 1704209872 Absolutely_Correct     3\n2     1 Class1 1704209852 Absolutely_Correct     3\n3     2 Class1 1704209838 Absolutely_Correct     3\n4     3 Class1 1704208923 Absolutely_Correct     3\n5     4 Class1 1704208359 Absolutely_Correct     4\n6     5 Class1 1704208330             Error1     0\n                       title_ID                      method memory timeconsume\n1 Question_bumGRTJ0c8p4v5D6eHZa Method_Cj9Ya2R7fZd6xs1q5mNQ    320           3\n2 Question_62XbhBvJ8NUSnApgDL94 Method_gj1NLb4Jn7URf9K2kQPd    356           3\n3 Question_ZTbD7mxr2OUp8Fz6iNjy Method_5Q4KoXthUuYz3bvrTDFm    196           2\n4 Question_xqlJkmRaP0otZcX4fK3W Method_m8vwGkEZc3TSW2xqYUoR    308           2\n5 Question_FNg8X9v5zcbB1tQrxHR3 Method_Cj9Ya2R7fZd6xs1q5mNQ    320           3\n6 Question_FNg8X9v5zcbB1tQrxHR3 Method_gj1NLb4Jn7URf9K2kQPd      0           5\n            student_ID\n1 8b6d1125760bd3939b6e\n2 8b6d1125760bd3939b6e\n3 8b6d1125760bd3939b6e\n4 63eef37311aaac915a45\n5 5d89810b20079366fcc2\n6 5d89810b20079366fcc2\n\n\nshow the code\nwrite.csv(submit_data, \"data/submit_data.csv\", row.names = FALSE)\n\n\nNow we have 3 data sets in total, which are:\n\nStudent information data\nQuestion title information\nSubmission record information\n\n\n\nShow the code\nstu_info &lt;- read.csv('data/Data_Studentinfo.csv')\ntit_info &lt;- read.csv('data/Data_Titleinfo.csv')\nsub_info &lt;- read.csv('data/submit_data.csv')\nsummary(stu_info)\n\n\n     index         student_ID            sex                 age       \n Min.   :   1.0   Length:1364        Length:1364        Min.   :18.00  \n 1st Qu.: 341.8   Class :character   Class :character   1st Qu.:19.00  \n Median : 682.5   Mode  :character   Mode  :character   Median :21.00  \n Mean   : 682.5                                         Mean   :21.05  \n 3rd Qu.:1023.2                                         3rd Qu.:23.00  \n Max.   :1364.0                                         Max.   :24.00  \n    major          \n Length:1364       \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nShow the code\nsummary(tit_info)\n\n\n     index         title_ID             score        knowledge        \n Min.   : 1.00   Length:44          Min.   :1.000   Length:44         \n 1st Qu.:11.75   Class :character   1st Qu.:2.750   Class :character  \n Median :22.50   Mode  :character   Median :3.000   Mode  :character  \n Mean   :22.50                      Mean   :2.636                     \n 3rd Qu.:33.25                      3rd Qu.:3.000                     \n Max.   :44.00                      Max.   :4.000                     \n sub_knowledge     \n Length:44         \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nShow the code\nsummary(sub_info)\n\n\n     index          class                time              state          \n Min.   :    0   Length:232818      Min.   :1.693e+09   Length:232818     \n 1st Qu.: 3880   Class :character   1st Qu.:1.697e+09   Class :character  \n Median : 7760   Mode  :character   Median :1.699e+09   Mode  :character  \n Mean   : 7967                      Mean   :1.699e+09                     \n 3rd Qu.:11640                      3rd Qu.:1.701e+09                     \n Max.   :20201                      Max.   :1.706e+09                     \n     score          title_ID            method              memory       \n Min.   :0.0000   Length:232818      Length:232818      Min.   :    0.0  \n 1st Qu.:0.0000   Class :character   Class :character   1st Qu.:  188.0  \n Median :0.0000   Mode  :character   Mode  :character   Median :  324.0  \n Mean   :0.8991                                         Mean   :  347.3  \n 3rd Qu.:2.0000                                         3rd Qu.:  356.0  \n Max.   :4.0000                                         Max.   :65536.0  \n timeconsume         student_ID       \n Length:232818      Length:232818     \n Class :character   Class :character  \n Mode  :character   Mode  :character"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Useful Tips",
    "section": "",
    "text": "Text formatting\nitalics, bold, bold italics\n*italics*, **bold**, ***bold italics \"***\nsuperscript2 / subscript2\nsuperscript^2^ / subscript~2~\nstrikethrough\n~~strikethrough~~\nverbatim code\n`verbatim code`\n\n\nTables\n| Right | Left | Default | Center |\n|------:|:-----|---------|:------:|\n|   12  |  12  |    12   |    12  |\n|  123  |  123 |   123   |   123  |\n|    1  |    1 |     1   |     1  |\n\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\n\nDiagrams\n```{mermaid}\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n```\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\n\n\nMargin Figures\nFigures that you create using code cells can be placed in the margin by using the column: margin code cell option. If the code produces more than one figure, each of the figures will be placed in the margin.\n#| column: margin"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on ex 1",
    "section": "",
    "text": "In this chapter, you will learn the basic principles and essential components of ggplot2. At the same time, you will gain hands-on experience on using these components to plot statistical graphics based on the principle of Layered Grammar of Graphics. By then end of this chapter you will be able to apply the essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics.\n\n\n\n\n\n\npacman::p_load(tidyverse)\n\n\n\n\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nexam_data &lt;- read_csv(\"Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\n\n\n\n\n is an R package for declaratively creating data-driven graphics based on The Grammar of Graphics\n\nIt is also part of the tidyverse family specially designed for visual exploration and communication.\n\n\nFor more detail, visit ggplot2 link.\n\n\n\nFirst, let us compare how R Graphics, the core graphical functions of Base R and ggplot plot a simple histogram.\n\nggplot2histogram\n\n\n\nlibrary(ggplot2)\nggplot(data=exam_data, aes(x=MATHS)) +\n  geom_histogram(bins=10, boundary=100, color=\"black\", fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nImportant: The transferable skills from ggplot2 are not the idiosyncrasies of plotting syntax, but a powerful way of thinking about visualisation, as a way of mapping between variables and the visual properties of geometric objects that you can perceive.\n\n\n\n\n\n\nBefore we getting started using ggplot2, it is important for us to understand the principles of Grammer of Graphics.\nGrammar of Graphics is a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. It was introduced by Leland Wilkinson (1999) Grammar of Graphics, Springer. The grammar of graphics is an answer to a question:\n\nWhat is a statistical graphic?\n\nIn the nutshell, Grammar of Graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\nA good grammar of graphics will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978). It also provides a strong foundation for understanding a diverse range of graphics. Furthermore, it may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\n\n\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics. Figure below shows the seven grammars of ggplot2.\n\nReference: Hadley Wickham (2010) “A layered grammar of graphics.” Journal of Computational and Graphical Statistics, vol. 19, no. 1, pp. 3–28.\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background.\n\n\n\n\n\nLet us call the ggplot() function using the code chunk on the right.\n\nggplot(data = exam_data)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify().\n\n\n\n\n\n\n\nAll aesthetics of a plot are specified in the aes() function call (in later part of this lesson, you will see that each geom layer can have its own aes specification)\n\nggplot(data=exam_data, \n       aes(x= MATHS))\n\n\n\n\n\n\n\nGeometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\n\n\nA plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\nFor complete list, please refer to here.\n\n\n\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe y scale is not very useful, in fact it is very misleading.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(\n  data = exam_data,\n  aes(x =  MATHS))+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote\nThe default bin is 30\n\n\n\n\n\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"white\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n\n\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"white\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis approach can be used to colour, fill and alpha of the geometric.\n\n\n\n\n\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\n\nSummaryBy gender\n\n\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data = exam_data,\n       aes(x = MATHS))+\n      geom_density()\n\n\n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)        \n\n\n\n\n\n\n\n\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4)               \n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\n\n\n\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)          \n\nWarning in geom_point(stat = \"summary\", fun.y = \"mean\", colour = \"red\", :\nIgnoring unknown parameters: `fun.y`\n\n\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTwo output above look the same but use different method\n\n\n\n\n\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\n\nwithout fit curvewith fit curveSmooth using lm\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() \n\n\n\n\n\n\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(linewidth=0.5)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\n\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)\n\n\n\n\n\n\n\n\nThe Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n\n\n\n\n\n\nImportant\n\n\n\n\ncoord_cartesian(): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out).\ncoord_flip(): a cartesian system with the x and y flipped.\ncoord_fixed(): a cartesian system with a “fixed” aspect ratio (e.g. 1.78 for a “widescreen” plot).\ncoord_quickmap(): a coordinate system that approximates a good aspect ratio for maps.\n\n\n\n\n\nBy the default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\nThe scatterplot on the right is slightly misleading because the y-aixs and x-axis range are not equal.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n\n\nTheme grayTheme classicTheme minimal\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#learning-outcome",
    "title": "Hands-on ex 1",
    "section": "",
    "text": "In this chapter, you will learn the basic principles and essential components of ggplot2. At the same time, you will gain hands-on experience on using these components to plot statistical graphics based on the principle of Layered Grammar of Graphics. By then end of this chapter you will be able to apply the essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "title": "Hands-on ex 1",
    "section": "",
    "text": "pacman::p_load(tidyverse)\n\n\n\n\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nexam_data &lt;- read_csv(\"Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "title": "Hands-on ex 1",
    "section": "",
    "text": "is an R package for declaratively creating data-driven graphics based on The Grammar of Graphics\n\nIt is also part of the tidyverse family specially designed for visual exploration and communication.\n\n\nFor more detail, visit ggplot2 link.\n\n\n\nFirst, let us compare how R Graphics, the core graphical functions of Base R and ggplot plot a simple histogram.\n\nggplot2histogram\n\n\n\nlibrary(ggplot2)\nggplot(data=exam_data, aes(x=MATHS)) +\n  geom_histogram(bins=10, boundary=100, color=\"black\", fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nImportant: The transferable skills from ggplot2 are not the idiosyncrasies of plotting syntax, but a powerful way of thinking about visualisation, as a way of mapping between variables and the visual properties of geometric objects that you can perceive."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "title": "Hands-on ex 1",
    "section": "",
    "text": "Before we getting started using ggplot2, it is important for us to understand the principles of Grammer of Graphics.\nGrammar of Graphics is a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. It was introduced by Leland Wilkinson (1999) Grammar of Graphics, Springer. The grammar of graphics is an answer to a question:\n\nWhat is a statistical graphic?\n\nIn the nutshell, Grammar of Graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\nA good grammar of graphics will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978). It also provides a strong foundation for understanding a diverse range of graphics. Furthermore, it may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\n\n\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics. Figure below shows the seven grammars of ggplot2.\n\nReference: Hadley Wickham (2010) “A layered grammar of graphics.” Journal of Computational and Graphical Statistics, vol. 19, no. 1, pp. 3–28.\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "Hands-on ex 1",
    "section": "",
    "text": "Let us call the ggplot() function using the code chunk on the right.\n\nggplot(data = exam_data)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "title": "Hands-on ex 1",
    "section": "",
    "text": "All aesthetics of a plot are specified in the aes() function call (in later part of this lesson, you will see that each geom layer can have its own aes specification)\n\nggplot(data=exam_data, \n       aes(x= MATHS))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "title": "Hands-on ex 1",
    "section": "",
    "text": "Geometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\n\n\nA plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\nFor complete list, please refer to here.\n\n\n\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe y scale is not very useful, in fact it is very misleading.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(\n  data = exam_data,\n  aes(x =  MATHS))+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote\nThe default bin is 30\n\n\n\n\n\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"white\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n\n\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"white\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis approach can be used to colour, fill and alpha of the geometric.\n\n\n\n\n\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\n\nSummaryBy gender\n\n\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data = exam_data,\n       aes(x = MATHS))+\n      geom_density()\n\n\n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands-on ex 1",
    "section": "",
    "text": "The Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4)               \n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\n\n\n\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)          \n\nWarning in geom_point(stat = \"summary\", fun.y = \"mean\", colour = \"red\", :\nIgnoring unknown parameters: `fun.y`\n\n\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTwo output above look the same but use different method\n\n\n\n\n\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\n\nwithout fit curvewith fit curveSmooth using lm\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() \n\n\n\n\n\n\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(linewidth=0.5)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "Hands-on ex 1",
    "section": "",
    "text": "Facetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\n\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "Hands-on ex 1",
    "section": "",
    "text": "The Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n\n\n\n\n\n\nImportant\n\n\n\n\ncoord_cartesian(): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out).\ncoord_flip(): a cartesian system with the x and y flipped.\ncoord_fixed(): a cartesian system with a “fixed” aspect ratio (e.g. 1.78 for a “widescreen” plot).\ncoord_quickmap(): a coordinate system that approximates a good aspect ratio for maps.\n\n\n\n\n\nBy the default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\nThe scatterplot on the right is slightly misleading because the y-aixs and x-axis range are not equal.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "title": "Hands-on ex 1",
    "section": "",
    "text": "Themes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n\n\nTheme grayTheme classicTheme minimal\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "title": "Hands-on ex 1",
    "section": "",
    "text": "Hadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands on ex 2",
    "section": "",
    "text": "In this chapter, you will be introduced to several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of this exercise, you will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package.\n\n\n\n\n\n\nIn this exercise, beside tidyverse, four R packages will be used. They are:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\n\npacman::p_load(ggrepel, patchwork, ggthemes, hrbrthemes, tidyverse)\n\n\n\n\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\n\n\n\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\ncodeplot\n\n\n\nggplot(data = exam_data,\n       aes(x = MATHS,\n           y = ENGLISH))+\n  geom_point()+\n  geom_smooth(method = lm,\n              size = 0.5)+\n  geom_label(aes(label = ID),\n             hjust = 0.5,\n             vjust = -0.5)+\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100))+\n  ggtitle(\"English vs Maths scores for Primary 3 \")\n\n\n\n\n\n\n\nggrepel  is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in our examples on the right.\n\nWe simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\n\n\ncodeplot\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\nggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\ncodeplot\n\n\n\nggplot(data = exam_data,\n                aes(x = MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"black\",\n                 fill = \"grey\")+\n  theme_gray()+\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\nRefer to this link to learn more about ggplot2 Themes\n\n\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\n\ncodeplot\n\n\n\nggplot(data = exam_data,\n                aes(x = MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"black\",\n                 fill = \"grey\")+\n  theme_economist()+\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\nIt also provides some extra geoms and scales for ‘ggplot2’. Consult this vignette to learn more.\n\n\n\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\ncodeplot\n\n\n\nggplot(data = exam_data,\n                aes(x = MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"black\",\n                 fill = \"grey\")+\n  theme_ipsum()+\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\ncodeplot\n\n\n\nggplot(data = exam_data,\n                aes(x = MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"black\",\n                 fill = \"grey\")+\n  theme_ipsum(axis_title_size = 15,\n              base_size = 15,\n              grid = \"y\")+\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines.\n\n\n\n\n\n\n\nIt is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, you will learn how to create composite plot by combining multiple graphs. First, let us create three statistical graphics by using the code chunk below.\n\ncodeplot\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\np1\n\np2\n\np3\n\n\n\n\n\n\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package. In this section, I am going to shared with you an ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n\n\nFigure in the tabset below shows a composite of two histograms created using patchwork. Note how simple the syntax used to create the plot!\n\ncodeplot\n\n\n\np1 + p2\n\n\n\n\n\n\n\n\n\n\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n“/” operator to stack two ggplot2 graphs,\n“|” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\nplotcode\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n(p1/p2)|p3\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo learn more about, refer to Plot Assembly.\n\n\n\n\n\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = '1')\n\n\n\n\n\n\n\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\np3 + inset_element(p2, \n                   left = 0, \n                   bottom = 0.6, \n                   right = 0.4, \n                   top = 1)\n\n\n\n\n\n\n\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\ncodeplot\n\n\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()&\ntheme(plot.title = element_text(size=8))\n\n\n\n\n\n\n\n\n\n\n\n\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "title": "Hands on ex 2",
    "section": "",
    "text": "In this chapter, you will be introduced to several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of this exercise, you will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands on ex 2",
    "section": "",
    "text": "In this exercise, beside tidyverse, four R packages will be used. They are:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\n\npacman::p_load(ggrepel, patchwork, ggthemes, hrbrthemes, tidyverse)\n\n\n\n\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Hands on ex 2",
    "section": "",
    "text": "One of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\ncodeplot\n\n\n\nggplot(data = exam_data,\n       aes(x = MATHS,\n           y = ENGLISH))+\n  geom_point()+\n  geom_smooth(method = lm,\n              size = 0.5)+\n  geom_label(aes(label = ID),\n             hjust = 0.5,\n             vjust = -0.5)+\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100))+\n  ggtitle(\"English vs Maths scores for Primary 3 \")\n\n\n\n\n\n\n\nggrepel  is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in our examples on the right.\n\nWe simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\n\n\ncodeplot\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Hands on ex 2",
    "section": "",
    "text": "ggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\ncodeplot\n\n\n\nggplot(data = exam_data,\n                aes(x = MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"black\",\n                 fill = \"grey\")+\n  theme_gray()+\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\nRefer to this link to learn more about ggplot2 Themes\n\n\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\n\ncodeplot\n\n\n\nggplot(data = exam_data,\n                aes(x = MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"black\",\n                 fill = \"grey\")+\n  theme_economist()+\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\nIt also provides some extra geoms and scales for ‘ggplot2’. Consult this vignette to learn more.\n\n\n\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\ncodeplot\n\n\n\nggplot(data = exam_data,\n                aes(x = MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"black\",\n                 fill = \"grey\")+\n  theme_ipsum()+\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\ncodeplot\n\n\n\nggplot(data = exam_data,\n                aes(x = MATHS))+\n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"black\",\n                 fill = \"grey\")+\n  theme_ipsum(axis_title_size = 15,\n              base_size = 15,\n              grid = \"y\")+\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "title": "Hands on ex 2",
    "section": "",
    "text": "It is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, you will learn how to create composite plot by combining multiple graphs. First, let us create three statistical graphics by using the code chunk below.\n\ncodeplot\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\np1\n\np2\n\np3\n\n\n\n\n\n\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package. In this section, I am going to shared with you an ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n\n\nFigure in the tabset below shows a composite of two histograms created using patchwork. Note how simple the syntax used to create the plot!\n\ncodeplot\n\n\n\np1 + p2\n\n\n\n\n\n\n\n\n\n\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n“/” operator to stack two ggplot2 graphs,\n“|” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\nplotcode\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n(p1/p2)|p3\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo learn more about, refer to Plot Assembly.\n\n\n\n\n\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = '1')\n\n\n\n\n\n\n\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\np3 + inset_element(p2, \n                   left = 0, \n                   bottom = 0.6, \n                   right = 0.4, \n                   top = 1)\n\n\n\n\n\n\n\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\ncodeplot\n\n\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()&\ntheme(plot.title = element_text(size=8))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "title": "Hands on ex 2",
    "section": "",
    "text": "Patchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "ggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n-   To provide alternative statistical inference methods by default.\n-   To follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the [APA](https://my.ilstu.edu/~jhkahn/apastats.html) gold standard for statistical reporting. For example, here are results from a robust t-test:\n\n\n\n\n\n\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam &lt;- read_csv('data/exam_data.csv')\nhead(exam)\n\n# A tibble: 6 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n6 Student306 3I    Female Malay        31    16      16\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)\n\n\n\n\n\n\n\n\nIn this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\nNotice that the output object car_resale is a tibble data frame.\n\n\n\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\nIn the code chunk, check_normality() of performance package.\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\ncheck_n &lt;- check_normality(model1)\n\nplot(check_n)\n\n\n\n\n\n\n\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\nplot(check_h)\n\n\n\n\n\n\n\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\n\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "ggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n-   To provide alternative statistical inference methods by default.\n-   To follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the [APA](https://my.ilstu.edu/~jhkahn/apastats.html) gold standard for statistical reporting. For example, here are results from a robust t-test:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-started",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam &lt;- read_csv('data/exam_data.csv')\nhead(exam)\n\n# A tibble: 6 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n6 Student306 3I    Female Malay        31    16      16\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-models",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "pacman::p_load(readxl, performance, parameters, see)\n\n\n\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\nNotice that the output object car_resale is a tibble data frame.\n\n\n\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\nIn the code chunk, check_normality() of performance package.\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\ncheck_n &lt;- check_normality(model1)\n\nplot(check_n)\n\n\n\n\n\n\n\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\nplot(check_h)\n\n\n\n\n\n\n\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\n\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 4",
    "section": "5.1 Installing and loading the packages",
    "text": "5.1 Installing and loading the packages\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#data-import",
    "title": "Hands-on Exercise 4",
    "section": "5.2 Data import",
    "text": "5.2 Data import\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 4",
    "section": "5.3 Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "5.3 Visualizing the uncertainty of point estimates: ggplot2 methods\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\n\n\n\n\n\nImportant\n\n\n\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\nIn this section, you will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nTip\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor the mathematical explanation, please refer to Slide 20 of Lesson 4.\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n5.3.1 Plotting standard error bars of point estimates\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nPlotCode\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\nTip\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\n\n\n\n\n5.3.2 Plotting confidence interval of point estimates\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nPlotCode\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\nTip\n\n\n\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\n\n\n\n\n\n5.3.3 Visualizing the uncertainty of point estimates with interactive error bars\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 4",
    "section": "5.4 Visualizing Uncertainty: ggdist package",
    "text": "5.4 Visualizing Uncertainty: ggdist package\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n5.4.1 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n5.4.2 Visualizing the uncertainty of point estimates: ggdist methods\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n5.4.3 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on Exercise 4",
    "section": "5.5 Visualizing Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "5.5 Visualizing Uncertainty with Hypothetical Outcome Plots (HOPs)\nStep 1: Installing ungeviz package\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nNote: You only need to perform this step once.\nStep 2: Launch the application in R\n\nlibrary(ungeviz)\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "title": "Hands-on Exercise 4",
    "section": "5.6 Visualizing Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "5.6 Visualizing Uncertainty with Hypothetical Outcome Plots (HOPs)\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "pacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse) \n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nCreate an interactive statistical graph by using ggiraph package.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\nTooltips can be customised.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)         \n\n\n\n\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)     \n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)   \n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)        \n\n\n\n\n\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)    \n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\n\n\n\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(),\nby using ggplotly()\n\n\nplot_ly() methodplot_ly() with colorggplotly() method\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\n\nCoordinated Multiple Views with plotly The creation of a coordinated linked plot by using plotly involves three steps: 1. highlight_key() of plotly package is used as shared data. 2. two scatterplots will be created by using ggplot2 functions. 3. lastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\n\n\n\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfurther reading"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "pacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse) \n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nCreate an interactive statistical graph by using ggiraph package.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\nTooltips can be customised.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)         \n\n\n\n\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)     \n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)   \n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)        \n\n\n\n\n\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)    \n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-graph",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-graph",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "There are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(),\nby using ggplotly()\n\n\nplot_ly() methodplot_ly() with colorggplotly() method\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\n\nCoordinated Multiple Views with plotly The creation of a coordinated linked plot by using plotly involves three steps: 1. highlight_key() of plotly package is used as shared data. 2. two scatterplots will be created by using ggplot2 functions. 3. lastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\nhighlight_key() simply creates an object of class crosstalk::SharedData."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#dt-package",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#dt-package",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "Data objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfurther reading"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#gganimate-methods",
    "title": "Hands-on Exercise 3",
    "section": "gganimate methods",
    "text": "gganimate methods\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\nStatic Bubble Plot\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\nAnimated Bubble Plot\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')      \n\n\n\n\nggplotly() method\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position=‘none’) should be used as shown in the plot and code chunk below.\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\nplot_ly()method\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands on Exercise 5",
    "section": "",
    "text": "In this hands-on exercise, the following R packages for handling, processing, wrangling, analysing and visualising text data will be used:\n\ntidytext, tidyverse (mainly readr, purrr, stringr, ggplot2)\nwidyr,\nwordcloud and ggwordcloud,\ntextplot (required igraph, tidygraph and ggraph, )\nDT,\nlubridate and hms.\n\n\npacman::p_load(tidytext, widyr, wordcloud, DT, ggwordcloud, textplot, lubridate, hms,\ntidyverse, tidygraph, ggraph, igraph, purrr)\n\n\n\n\n\n\n\n\nnews20 &lt;- ('data/20news')\n\n\n\n\n\nread_folder &lt;- function(infolder) {\n  tibble(file = dir(infolder, \n                    full.names = TRUE)) %&gt;%\n    mutate(text = map(file, \n                      read_lines)) %&gt;%\n    transmute(id = basename(file), \n              text) %&gt;%\n    unnest(text)\n}\n\n\n\n\n\nraw_text &lt;- tibble(folder = \n                     dir(news20, \n                         full.names = TRUE)) %&gt;%\n  mutate(folder_out = map(folder, \n                          read_folder)) %&gt;%\n  unnest(cols = c(folder_out)) %&gt;%\n  transmute(newsgroup = basename(folder), \n            id, text)\nwrite_rds(raw_text, \"data/news20.rds\")\n\n\n\n\n\n\n\nTip\n\n\n\n\nread_lines() of readr package is used to read up to n_max lines from a file.\nmap() of purrr package is used to transform their input by applying a function to each element of a list and returning an object of the same length as the input.\nunnest() of dplyr package is used to flatten a list-column of data frames back out into regular columns.\nmutate() of dplyr is used to add new variables and preserves existing ones;\ntransmute() of dplyr is used to add new variables and drops existing ones.\nread_rds() is used to save the extracted and combined data frame as rds file for future use.\n\n\n\n\n\n\n\nFigure below shows the frequency of messages by newsgroup.\n\nraw_text %&gt;%\n  group_by(newsgroup) %&gt;%\n  summarize(messages = n_distinct(id)) %&gt;%\n  ggplot(aes(messages, newsgroup)) +\n  geom_col(fill = \"lightblue\") +\n  labs(y = NULL)\n\n\n\n\n\n\n\n\nUsing tidy data principles in processing, analysing and visualising text data.\nMuch of the infrastructure needed for text mining with tidy data frames already exists in packages like ‘dplyr’, ‘broom’, ‘tidyr’, and ‘ggplot2’.\n\nFigure below shows the workflow using tidytext approach for processing and visualising text data.\n\n\n\nNotice that each message has some structure and extra text that we don’t want to include in our analysis. For example, every message has a header, containing field such as “from:” or “in_reply_to:” that describe the message. Some also have automated email signatures, which occur after a line like “–”.\n\ncleaned_text &lt;- raw_text %&gt;%\n  group_by(newsgroup, id) %&gt;%\n  filter(cumsum(text == \"\") &gt; 0,\n         cumsum(str_detect(\n           text, \"^--\")) == 0) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nTip\n\n\n\n\ncumsum() of base R is used to return a vector whose elements are the cumulative sums of the elements of the argument.\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\n\n\n\n\n\n\nIn this code chunk below, regular expressions are used to remove with nested text representing quotes from other users.\n\ncleaned_text &lt;- cleaned_text %&gt;%\n  filter(str_detect(text, \"^[^&gt;]+[A-Za-z\\\\d]\")\n         | text == \"\",\n         !str_detect(text, \n                     \"writes(:|\\\\.\\\\.\\\\.)$\"),\n         !str_detect(text, \n                     \"^In article &lt;\")\n  )\n\n\n\n\n\n\n\nTip\n\n\n\n\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\nfilter() of dplyr package is used to subset a data frame, retaining all rows that satisfy the specified conditions.\n\n\n\n\n\n\nIn this code chunk below, unnest_tokens() of tidytext package is used to split the dataset into tokens, while stop_words() is used to remove stop-words.\n\nusenet_words &lt;- cleaned_text %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nNow that we’ve removed the headers, signatures, and formatting, we can start exploring common words. For starters, we could find the most common words in the entire dataset, or within particular newsgroups.\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\n# A tibble: 5,542 × 2\n   word           n\n   &lt;chr&gt;      &lt;int&gt;\n 1 people        57\n 2 time          50\n 3 jesus         47\n 4 god           44\n 5 message       40\n 6 br            27\n 7 bible         23\n 8 drive         23\n 9 homosexual    23\n10 read          22\n# ℹ 5,532 more rows\n\n\nInstead of counting individual word, you can also count words within by newsgroup by using the code chunk below.\n\nwords_by_newsgroup &lt;- usenet_words %&gt;%\n  count(newsgroup, word, sort = TRUE) %&gt;%\n  ungroup()\n\n\n\n\nIn this code chunk below, wordcloud() of wordcloud package is used to plot a static wordcloud.\n\nwordcloud(words_by_newsgroup$word,\n          words_by_newsgroup$n,\n          max.words = 300)\n\n\n\n\n\n\n\nThe wordcloud below is plotted by using ggwordcloud package.\n\nset.seed(1234)\n\nwords_by_newsgroup %&gt;%\n  filter(n &gt; 0) %&gt;%\nggplot(aes(label = word,\n           size = n)) +\n  geom_text_wordcloud() +\n  theme_minimal() +\n  facet_wrap(~newsgroup)\n\n\n\n\n\n\n\n\n\ntf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection of corpus.\n\n\n\n\nThe code chunk below uses bind_tf_idf() of tidytext to compute and bind the term frequency, inverse document frequency and ti-idf of a tidy text dataset to the dataset.\n\ntf_idf &lt;- words_by_newsgroup %&gt;%\n  bind_tf_idf(word, newsgroup, n) %&gt;%\n  arrange(desc(tf_idf))\ndatatable(tf_idf)\n\n\n\n\n\n\n\n\n\nThe code chunk below uses datatable() of DT package to create a html table that allows pagination of rows and columns.\n\nDT::datatable(tf_idf, filter = 'top') %&gt;% \n  formatRound(columns = c('tf', 'idf', \n                          'tf_idf'), \n              digits = 3) %&gt;%\n  formatStyle(0, \n              target = 'row', \n              lineHeight='25%')\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nfilter() argument is used to turn control the filter UI.\nformatRound() is used to customise the values format. The argument digits define the number of decimal places.\nformatStyle() is used to customise the output table. In this example, the arguments target and lineHeight are used to reduce the line height by 25%.\n\n\n\nTo learn more about customising DT’s table, visit this link.\n\n\n\nFacet bar charts technique is used to visualise the tf-idf values of science related newsgroup.\n\ntf_idf %&gt;%\n  filter(str_detect(newsgroup, \"^sci\\\\.\")) %&gt;%\n  group_by(newsgroup) %&gt;%\n  slice_max(tf_idf, \n            n = 12) %&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, \n                        tf_idf)) %&gt;%\n  ggplot(aes(tf_idf, \n             word, \n             fill = newsgroup)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ newsgroup, \n             scales = \"free\") +\n  labs(x = \"tf-idf\", \n       y = NULL)\n\n\n\n\n\n\n\n\nTo count the number of times that two words appear within the same document, or to see how correlated they are.\nMost operations for finding pairwise counts or correlations need to turn the data into a wide matrix first.\nwidyr package first ‘casts’ a tidy dataset into a wide matrix, performs an operation such as a correlation on it, then re-tidies the result.\n\n\nIn this code chunk below, pairwise_cor() of widyr package is used to compute the correlation between newsgroup based on the common words found.\n\nnewsgroup_cors &lt;- words_by_newsgroup %&gt;%\n  pairwise_cor(newsgroup, \n               word, \n               n, \n               sort = TRUE)\nnewsgroup_cors\n\n# A tibble: 380 × 3\n   item1                    item2                    correlation\n   &lt;chr&gt;                    &lt;chr&gt;                          &lt;dbl&gt;\n 1 talk.religion.misc       soc.religion.christian         0.258\n 2 soc.religion.christian   talk.religion.misc             0.258\n 3 soc.religion.christian   alt.atheism                    0.207\n 4 alt.atheism              soc.religion.christian         0.207\n 5 comp.sys.ibm.pc.hardware comp.sys.mac.hardware          0.204\n 6 comp.sys.mac.hardware    comp.sys.ibm.pc.hardware       0.204\n 7 talk.religion.misc       alt.atheism                    0.170\n 8 alt.atheism              talk.religion.misc             0.170\n 9 comp.graphics            comp.os.ms-windows.misc        0.149\n10 comp.os.ms-windows.misc  comp.graphics                  0.149\n# ℹ 370 more rows\n\n\n\n\n\nNow, we can visualise the relationship between newgroups in network graph as shown below.\n\nset.seed(2017)\n\nnewsgroup_cors %&gt;%\n  filter(correlation &gt; .025) %&gt;%\n  graph_from_data_frame() %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = correlation, \n                     width = correlation)) +\n  geom_node_point(size = 6, \n                  color = \"lightblue\") +\n  geom_node_text(aes(label = name),\n                 color = \"red\",\n                 repel = TRUE) +\n  theme_void()\n\n\n\n\n\n\n\nIn this code chunk below, a bigram data frame is created by using unnest_tokens() of tidytext\n\nbigrams &lt;- cleaned_text %&gt;%\n  unnest_tokens(bigram, \n                text, \n                token = \"ngrams\", \n                n = 2)\nbigrams\n\n# A tibble: 28,824 × 3\n   newsgroup   id    bigram    \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;     \n 1 alt.atheism 54256 &lt;NA&gt;      \n 2 alt.atheism 54256 &lt;NA&gt;      \n 3 alt.atheism 54256 as i      \n 4 alt.atheism 54256 i don't   \n 5 alt.atheism 54256 don't know\n 6 alt.atheism 54256 know this \n 7 alt.atheism 54256 this book \n 8 alt.atheism 54256 book i    \n 9 alt.atheism 54256 i will    \n10 alt.atheism 54256 will use  \n# ℹ 28,814 more rows\n\n\nThe code chunk is used to count and sort the bigram data frame ascendingly.\n\nbigrams_count &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  count(bigram, sort = TRUE)\nbigrams_count\n\n# A tibble: 19,885 × 2\n   bigram       n\n   &lt;chr&gt;    &lt;int&gt;\n 1 of the     169\n 2 in the     113\n 3 to the      74\n 4 to be       59\n 5 for the     52\n 6 i have      48\n 7 that the    47\n 8 if you      40\n 9 on the      39\n10 it is       38\n# ℹ 19,875 more rows\n\n\nThe code chunk below is used to seperate the bigram into two words.\n\nbigrams_separated &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), \n           sep = \" \")\n\nbigrams_filtered &lt;- bigrams_separated %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\nbigrams_filtered\n\n# A tibble: 4,604 × 4\n   newsgroup   id    word1        word2        \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;        \n 1 alt.atheism 54256 defines      god          \n 2 alt.atheism 54256 term         preclues     \n 3 alt.atheism 54256 science      ideas        \n 4 alt.atheism 54256 ideas        drawn        \n 5 alt.atheism 54256 supernatural precludes    \n 6 alt.atheism 54256 scientific   assertions   \n 7 alt.atheism 54256 religious    dogma        \n 8 alt.atheism 54256 religion     involves     \n 9 alt.atheism 54256 involves     circumventing\n10 alt.atheism 54256 gain         absolute     \n# ℹ 4,594 more rows\n\n\n\nbigram_counts &lt;- bigrams_filtered %&gt;% \n  count(word1, word2, sort = TRUE)\nbigram_counts\n\n# A tibble: 4,135 × 3\n   word1   word2     n\n   &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;\n 1 1       2        12\n 2 1       3        12\n 3 static  void     10\n 4 time    pad      10\n 5 1       4         8\n 6 infield fly       7\n 7 mat     28        6\n 8 vv      vv        6\n 9 1       5         5\n10 cock    crow      5\n# ℹ 4,125 more rows\n\n\n\n\n\nIn the code chunk below, a network graph is created by using graph_from_data_frame() of igraph package.\n\nbigram_graph &lt;- bigram_counts %&gt;%\n  filter(n &gt; 3) %&gt;%\n  graph_from_data_frame()\nbigram_graph\n\nIGRAPH 2d45ab4 DN-- 40 24 -- \n+ attr: name (v/c), n (e/n)\n+ edges from 2d45ab4 (vertex names):\n [1] 1          -&gt;2           1          -&gt;3           static     -&gt;void       \n [4] time       -&gt;pad         1          -&gt;4           infield    -&gt;fly        \n [7] mat        -&gt;28          vv         -&gt;vv          1          -&gt;5          \n[10] cock       -&gt;crow        noticeshell-&gt;widget      27         -&gt;1993       \n[13] 3          -&gt;4           child      -&gt;molestation cock       -&gt;crew       \n[16] gun        -&gt;violence    heat       -&gt;sink        homosexual -&gt;male       \n[19] homosexual -&gt;women       include    -&gt;xol         mary       -&gt;magdalene  \n[22] read       -&gt;write       rev        -&gt;20          tt         -&gt;ee         \n\n\n\n\n\nIn this code chunk below, ggraph package is used to plot the bigram.\n\nset.seed(1234)\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link() +\n  geom_node_point() +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1)\n\n\n\n\n\n\n\n\nset.seed(1234)\n\na &lt;- grid::arrow(type = \"closed\", \n                 length = unit(.15,\n                               \"inches\"))\n\nggraph(bigram_graph, \n       layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), \n                 show.legend = FALSE,\n                 arrow = a, \n                 end_cap = circle(.07,\n                                  'inches')) +\n  geom_node_point(color = \"lightblue\", \n                  size = 5) +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1) +\n  theme_void()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "title": "Hands on Exercise 5",
    "section": "",
    "text": "In this hands-on exercise, the following R packages for handling, processing, wrangling, analysing and visualising text data will be used:\n\ntidytext, tidyverse (mainly readr, purrr, stringr, ggplot2)\nwidyr,\nwordcloud and ggwordcloud,\ntextplot (required igraph, tidygraph and ggraph, )\nDT,\nlubridate and hms.\n\n\npacman::p_load(tidytext, widyr, wordcloud, DT, ggwordcloud, textplot, lubridate, hms,\ntidyverse, tidygraph, ggraph, igraph, purrr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "title": "Hands on Exercise 5",
    "section": "",
    "text": "news20 &lt;- ('data/20news')\n\n\n\n\n\nread_folder &lt;- function(infolder) {\n  tibble(file = dir(infolder, \n                    full.names = TRUE)) %&gt;%\n    mutate(text = map(file, \n                      read_lines)) %&gt;%\n    transmute(id = basename(file), \n              text) %&gt;%\n    unnest(text)\n}\n\n\n\n\n\nraw_text &lt;- tibble(folder = \n                     dir(news20, \n                         full.names = TRUE)) %&gt;%\n  mutate(folder_out = map(folder, \n                          read_folder)) %&gt;%\n  unnest(cols = c(folder_out)) %&gt;%\n  transmute(newsgroup = basename(folder), \n            id, text)\nwrite_rds(raw_text, \"data/news20.rds\")\n\n\n\n\n\n\n\nTip\n\n\n\n\nread_lines() of readr package is used to read up to n_max lines from a file.\nmap() of purrr package is used to transform their input by applying a function to each element of a list and returning an object of the same length as the input.\nunnest() of dplyr package is used to flatten a list-column of data frames back out into regular columns.\nmutate() of dplyr is used to add new variables and preserves existing ones;\ntransmute() of dplyr is used to add new variables and drops existing ones.\nread_rds() is used to save the extracted and combined data frame as rds file for future use."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#initial-eda",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#initial-eda",
    "title": "Hands on Exercise 5",
    "section": "",
    "text": "Figure below shows the frequency of messages by newsgroup.\n\nraw_text %&gt;%\n  group_by(newsgroup) %&gt;%\n  summarize(messages = n_distinct(id)) %&gt;%\n  ggplot(aes(messages, newsgroup)) +\n  geom_col(fill = \"lightblue\") +\n  labs(y = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#introducing-tidytext",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#introducing-tidytext",
    "title": "Hands on Exercise 5",
    "section": "",
    "text": "Using tidy data principles in processing, analysing and visualising text data.\nMuch of the infrastructure needed for text mining with tidy data frames already exists in packages like ‘dplyr’, ‘broom’, ‘tidyr’, and ‘ggplot2’.\n\nFigure below shows the workflow using tidytext approach for processing and visualising text data.\n\n\n\nNotice that each message has some structure and extra text that we don’t want to include in our analysis. For example, every message has a header, containing field such as “from:” or “in_reply_to:” that describe the message. Some also have automated email signatures, which occur after a line like “–”.\n\ncleaned_text &lt;- raw_text %&gt;%\n  group_by(newsgroup, id) %&gt;%\n  filter(cumsum(text == \"\") &gt; 0,\n         cumsum(str_detect(\n           text, \"^--\")) == 0) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nTip\n\n\n\n\ncumsum() of base R is used to return a vector whose elements are the cumulative sums of the elements of the argument.\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\n\n\n\n\n\n\nIn this code chunk below, regular expressions are used to remove with nested text representing quotes from other users.\n\ncleaned_text &lt;- cleaned_text %&gt;%\n  filter(str_detect(text, \"^[^&gt;]+[A-Za-z\\\\d]\")\n         | text == \"\",\n         !str_detect(text, \n                     \"writes(:|\\\\.\\\\.\\\\.)$\"),\n         !str_detect(text, \n                     \"^In article &lt;\")\n  )\n\n\n\n\n\n\n\nTip\n\n\n\n\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\nfilter() of dplyr package is used to subset a data frame, retaining all rows that satisfy the specified conditions.\n\n\n\n\n\n\nIn this code chunk below, unnest_tokens() of tidytext package is used to split the dataset into tokens, while stop_words() is used to remove stop-words.\n\nusenet_words &lt;- cleaned_text %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nNow that we’ve removed the headers, signatures, and formatting, we can start exploring common words. For starters, we could find the most common words in the entire dataset, or within particular newsgroups.\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\n# A tibble: 5,542 × 2\n   word           n\n   &lt;chr&gt;      &lt;int&gt;\n 1 people        57\n 2 time          50\n 3 jesus         47\n 4 god           44\n 5 message       40\n 6 br            27\n 7 bible         23\n 8 drive         23\n 9 homosexual    23\n10 read          22\n# ℹ 5,532 more rows\n\n\nInstead of counting individual word, you can also count words within by newsgroup by using the code chunk below.\n\nwords_by_newsgroup &lt;- usenet_words %&gt;%\n  count(newsgroup, word, sort = TRUE) %&gt;%\n  ungroup()\n\n\n\n\nIn this code chunk below, wordcloud() of wordcloud package is used to plot a static wordcloud.\n\nwordcloud(words_by_newsgroup$word,\n          words_by_newsgroup$n,\n          max.words = 300)\n\n\n\n\n\n\n\nThe wordcloud below is plotted by using ggwordcloud package.\n\nset.seed(1234)\n\nwords_by_newsgroup %&gt;%\n  filter(n &gt; 0) %&gt;%\nggplot(aes(label = word,\n           size = n)) +\n  geom_text_wordcloud() +\n  theme_minimal() +\n  facet_wrap(~newsgroup)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic-concept-of-tf-idf",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic-concept-of-tf-idf",
    "title": "Hands on Exercise 5",
    "section": "",
    "text": "tf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection of corpus.\n\n\n\n\nThe code chunk below uses bind_tf_idf() of tidytext to compute and bind the term frequency, inverse document frequency and ti-idf of a tidy text dataset to the dataset.\n\ntf_idf &lt;- words_by_newsgroup %&gt;%\n  bind_tf_idf(word, newsgroup, n) %&gt;%\n  arrange(desc(tf_idf))\ndatatable(tf_idf)\n\n\n\n\n\n\n\n\n\nThe code chunk below uses datatable() of DT package to create a html table that allows pagination of rows and columns.\n\nDT::datatable(tf_idf, filter = 'top') %&gt;% \n  formatRound(columns = c('tf', 'idf', \n                          'tf_idf'), \n              digits = 3) %&gt;%\n  formatStyle(0, \n              target = 'row', \n              lineHeight='25%')\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nfilter() argument is used to turn control the filter UI.\nformatRound() is used to customise the values format. The argument digits define the number of decimal places.\nformatStyle() is used to customise the output table. In this example, the arguments target and lineHeight are used to reduce the line height by 25%.\n\n\n\nTo learn more about customising DT’s table, visit this link.\n\n\n\nFacet bar charts technique is used to visualise the tf-idf values of science related newsgroup.\n\ntf_idf %&gt;%\n  filter(str_detect(newsgroup, \"^sci\\\\.\")) %&gt;%\n  group_by(newsgroup) %&gt;%\n  slice_max(tf_idf, \n            n = 12) %&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, \n                        tf_idf)) %&gt;%\n  ggplot(aes(tf_idf, \n             word, \n             fill = newsgroup)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ newsgroup, \n             scales = \"free\") +\n  labs(x = \"tf-idf\", \n       y = NULL)\n\n\n\n\n\n\n\n\nTo count the number of times that two words appear within the same document, or to see how correlated they are.\nMost operations for finding pairwise counts or correlations need to turn the data into a wide matrix first.\nwidyr package first ‘casts’ a tidy dataset into a wide matrix, performs an operation such as a correlation on it, then re-tidies the result.\n\n\nIn this code chunk below, pairwise_cor() of widyr package is used to compute the correlation between newsgroup based on the common words found.\n\nnewsgroup_cors &lt;- words_by_newsgroup %&gt;%\n  pairwise_cor(newsgroup, \n               word, \n               n, \n               sort = TRUE)\nnewsgroup_cors\n\n# A tibble: 380 × 3\n   item1                    item2                    correlation\n   &lt;chr&gt;                    &lt;chr&gt;                          &lt;dbl&gt;\n 1 talk.religion.misc       soc.religion.christian         0.258\n 2 soc.religion.christian   talk.religion.misc             0.258\n 3 soc.religion.christian   alt.atheism                    0.207\n 4 alt.atheism              soc.religion.christian         0.207\n 5 comp.sys.ibm.pc.hardware comp.sys.mac.hardware          0.204\n 6 comp.sys.mac.hardware    comp.sys.ibm.pc.hardware       0.204\n 7 talk.religion.misc       alt.atheism                    0.170\n 8 alt.atheism              talk.religion.misc             0.170\n 9 comp.graphics            comp.os.ms-windows.misc        0.149\n10 comp.os.ms-windows.misc  comp.graphics                  0.149\n# ℹ 370 more rows\n\n\n\n\n\nNow, we can visualise the relationship between newgroups in network graph as shown below.\n\nset.seed(2017)\n\nnewsgroup_cors %&gt;%\n  filter(correlation &gt; .025) %&gt;%\n  graph_from_data_frame() %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = correlation, \n                     width = correlation)) +\n  geom_node_point(size = 6, \n                  color = \"lightblue\") +\n  geom_node_text(aes(label = name),\n                 color = \"red\",\n                 repel = TRUE) +\n  theme_void()\n\n\n\n\n\n\n\nIn this code chunk below, a bigram data frame is created by using unnest_tokens() of tidytext\n\nbigrams &lt;- cleaned_text %&gt;%\n  unnest_tokens(bigram, \n                text, \n                token = \"ngrams\", \n                n = 2)\nbigrams\n\n# A tibble: 28,824 × 3\n   newsgroup   id    bigram    \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;     \n 1 alt.atheism 54256 &lt;NA&gt;      \n 2 alt.atheism 54256 &lt;NA&gt;      \n 3 alt.atheism 54256 as i      \n 4 alt.atheism 54256 i don't   \n 5 alt.atheism 54256 don't know\n 6 alt.atheism 54256 know this \n 7 alt.atheism 54256 this book \n 8 alt.atheism 54256 book i    \n 9 alt.atheism 54256 i will    \n10 alt.atheism 54256 will use  \n# ℹ 28,814 more rows\n\n\nThe code chunk is used to count and sort the bigram data frame ascendingly.\n\nbigrams_count &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  count(bigram, sort = TRUE)\nbigrams_count\n\n# A tibble: 19,885 × 2\n   bigram       n\n   &lt;chr&gt;    &lt;int&gt;\n 1 of the     169\n 2 in the     113\n 3 to the      74\n 4 to be       59\n 5 for the     52\n 6 i have      48\n 7 that the    47\n 8 if you      40\n 9 on the      39\n10 it is       38\n# ℹ 19,875 more rows\n\n\nThe code chunk below is used to seperate the bigram into two words.\n\nbigrams_separated &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), \n           sep = \" \")\n\nbigrams_filtered &lt;- bigrams_separated %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\nbigrams_filtered\n\n# A tibble: 4,604 × 4\n   newsgroup   id    word1        word2        \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;        \n 1 alt.atheism 54256 defines      god          \n 2 alt.atheism 54256 term         preclues     \n 3 alt.atheism 54256 science      ideas        \n 4 alt.atheism 54256 ideas        drawn        \n 5 alt.atheism 54256 supernatural precludes    \n 6 alt.atheism 54256 scientific   assertions   \n 7 alt.atheism 54256 religious    dogma        \n 8 alt.atheism 54256 religion     involves     \n 9 alt.atheism 54256 involves     circumventing\n10 alt.atheism 54256 gain         absolute     \n# ℹ 4,594 more rows\n\n\n\nbigram_counts &lt;- bigrams_filtered %&gt;% \n  count(word1, word2, sort = TRUE)\nbigram_counts\n\n# A tibble: 4,135 × 3\n   word1   word2     n\n   &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;\n 1 1       2        12\n 2 1       3        12\n 3 static  void     10\n 4 time    pad      10\n 5 1       4         8\n 6 infield fly       7\n 7 mat     28        6\n 8 vv      vv        6\n 9 1       5         5\n10 cock    crow      5\n# ℹ 4,125 more rows\n\n\n\n\n\nIn the code chunk below, a network graph is created by using graph_from_data_frame() of igraph package.\n\nbigram_graph &lt;- bigram_counts %&gt;%\n  filter(n &gt; 3) %&gt;%\n  graph_from_data_frame()\nbigram_graph\n\nIGRAPH 2d45ab4 DN-- 40 24 -- \n+ attr: name (v/c), n (e/n)\n+ edges from 2d45ab4 (vertex names):\n [1] 1          -&gt;2           1          -&gt;3           static     -&gt;void       \n [4] time       -&gt;pad         1          -&gt;4           infield    -&gt;fly        \n [7] mat        -&gt;28          vv         -&gt;vv          1          -&gt;5          \n[10] cock       -&gt;crow        noticeshell-&gt;widget      27         -&gt;1993       \n[13] 3          -&gt;4           child      -&gt;molestation cock       -&gt;crew       \n[16] gun        -&gt;violence    heat       -&gt;sink        homosexual -&gt;male       \n[19] homosexual -&gt;women       include    -&gt;xol         mary       -&gt;magdalene  \n[22] read       -&gt;write       rev        -&gt;20          tt         -&gt;ee         \n\n\n\n\n\nIn this code chunk below, ggraph package is used to plot the bigram.\n\nset.seed(1234)\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link() +\n  geom_node_point() +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1)\n\n\n\n\n\n\n\n\nset.seed(1234)\n\na &lt;- grid::arrow(type = \"closed\", \n                 length = unit(.15,\n                               \"inches\"))\n\nggraph(bigram_graph, \n       layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), \n                 show.legend = FALSE,\n                 arrow = a, \n                 end_cap = circle(.07,\n                                  'inches')) +\n  geom_node_point(color = \"lightblue\", \n                  size = 5) +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1) +\n  theme_void()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS-WangYuhui",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications. In this website, you will find my coursework prepared for this course.\n\nImaginary Data AnalystActual Data Analyst"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take Home Exercise 1: Creating data visualisation beyond default",
    "section": "",
    "text": "There are two major residential property market in Singapore, namely public and private housing. Public housing aims to meet the basic need of the general public with monthly household income less than or equal to S$14,000. For families with monthly household income more than S$14,000, they need to turn to the private residential market.\nAssuming the role of a graphical editor of a median company, you are requested to prepare minimum two and maximum three data visualisation to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024.\n\n\n\nTo accomplish the task, transaction data of REALIS will be used. It is a complete set of the private residential property transaction data from 1st January 2023 to 31st March.\n\ndata1 &lt;- read.csv(\"data/ResidentialTransaction20240414220633.csv\")\ndata2 &lt;- read.csv(\"data/ResidentialTransaction20240308161109.csv\")\ndata3 &lt;- read.csv(\"data/ResidentialTransaction20240308161009.csv\")\ndata4 &lt;- read.csv(\"data/ResidentialTransaction20240308160736.csv\")\ndata5 &lt;- read.csv(\"data/ResidentialTransaction20240308160536.csv\")\n\nrpm &lt;- rbind(data1, data2, data3, data4, data5)\n# rpm refers to residential property market data"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background-and-task",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background-and-task",
    "title": "Take Home Exercise 1: Creating data visualisation beyond default",
    "section": "",
    "text": "There are two major residential property market in Singapore, namely public and private housing. Public housing aims to meet the basic need of the general public with monthly household income less than or equal to S$14,000. For families with monthly household income more than S$14,000, they need to turn to the private residential market.\nAssuming the role of a graphical editor of a median company, you are requested to prepare minimum two and maximum three data visualisation to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data",
    "title": "Take Home Exercise 1: Creating data visualisation beyond default",
    "section": "",
    "text": "To accomplish the task, transaction data of REALIS will be used. It is a complete set of the private residential property transaction data from 1st January 2023 to 31st March.\n\ndata1 &lt;- read.csv(\"data/ResidentialTransaction20240414220633.csv\")\ndata2 &lt;- read.csv(\"data/ResidentialTransaction20240308161109.csv\")\ndata3 &lt;- read.csv(\"data/ResidentialTransaction20240308161009.csv\")\ndata4 &lt;- read.csv(\"data/ResidentialTransaction20240308160736.csv\")\ndata5 &lt;- read.csv(\"data/ResidentialTransaction20240308160536.csv\")\n\nrpm &lt;- rbind(data1, data2, data3, data4, data5)\n# rpm refers to residential property market data"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#convert-and-select-the-column",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#convert-and-select-the-column",
    "title": "Take Home Exercise 1: Creating data visualisation beyond default",
    "section": "3.1 Convert and select the column",
    "text": "3.1 Convert and select the column\nFirst, let’s see the type of each column\n\nrpm1 &lt;- read_csv(\"data/rpm.csv\")\n\nWe can see there are 22 columns in total, 12 of them are in characters type and 10 of them are in numbers type. Now we select the column we need and convert them to the right type.\n\n\n\nColumn\nType\n\n\n\n\nProject Name\ncharacter\n\n\nTransacted Price\nnumber\n\n\nSale Date\ndate\n\n\nType of Sale\ncharacter\n\n\nType of Area\ncharacter\n\n\nArea(SQM)\nnumber\n\n\nUnit Price(Per SQM)\nnumber\n\n\nProperty Type\ncharacter\n\n\nCompletion Date\nnumber (set all ‘Uncompleted’ as 2030\n\n\nPurchaser Address Indicator\ncharacter\n\n\nPlanning Region\ncharacter\n\n\nPlanning Area\ncharacter\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nSet all uncompleted project date as 2030 to easier further analysis.\n\n\n\n\n\nShow the code\nrpm_processed &lt;- rpm1 %&gt;%\n  select(\n    Project.Name = Project.Name,\n    Transacted.Price.... = Transacted.Price....,\n    Sale.Date = Sale.Date,\n    Type.of.Sale = Type.of.Sale,\n    Type.of.Area = Type.of.Area,\n    Area..SQM. = Area..SQM.,\n    Unit.Price....PSM. = Unit.Price....PSM.,\n    Property.Type = Property.Type,\n    Completion.Date = Completion.Date,\n    Purchaser.Address.Indicator = Purchaser.Address.Indicator,\n    Planning.Region = Planning.Region,\n    Planning.Area = Planning.Area\n  ) %&gt;%\n  mutate(\n    Project.Name = as.character(Project.Name),\n    Transacted.Price.... = as.numeric(Transacted.Price....),\n    Sale.Date = as.Date(Sale.Date),\n    Type.of.Sale = as.character(Type.of.Sale),\n    Type.of.Area = as.character(Type.of.Area),\n    Area..SQM. = as.numeric(Area..SQM.),\n    Unit.Price....PSM. = as.numeric(Unit.Price....PSM.),\n    Property.Type = as.character(Property.Type),\n    Completion.Date = ifelse(Completion.Date == \"Uncompleted\", 2030, as.numeric(Completion.Date)),\n    Purchaser.Address.Indicator = as.character(Purchaser.Address.Indicator),\n    Planning.Region = as.character(Planning.Region),\n    Planning.Area = as.character(Planning.Area)\n  )\nprint(rpm_processed)\n\n\n# A tibble: 26,806 × 12\n   Project.Name        Transacted.Price.... Sale.Date  Type.of.Sale Type.of.Area\n   &lt;chr&gt;                              &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;        &lt;chr&gt;       \n 1 THE LANDMARK                     2726888 2024-01-01 New Sale     Strata      \n 2 POLLEN COLLECTION                3850000 2024-01-01 New Sale     Land        \n 3 SKY EDEN@BEDOK                   2346000 2024-01-01 New Sale     Strata      \n 4 TERRA HILL                       2190000 2024-01-01 New Sale     Strata      \n 5 PINETREE HILL                    1954000 2024-01-01 New Sale     Strata      \n 6 THE RESERVE RESIDE…              3412201 2024-01-01 New Sale     Strata      \n 7 SUMMER VILLAS                    2960000 2024-01-02 Resale       Strata      \n 8 THE MINTON                       1840000 2024-01-02 Resale       Strata      \n 9 SEMBAWANG HILLS ES…              4200000 2024-01-02 Resale       Land        \n10 NV RESIDENCES                    1350000 2024-01-02 Resale       Strata      \n# ℹ 26,796 more rows\n# ℹ 7 more variables: Area..SQM. &lt;dbl&gt;, Unit.Price....PSM. &lt;dbl&gt;,\n#   Property.Type &lt;chr&gt;, Completion.Date &lt;dbl&gt;,\n#   Purchaser.Address.Indicator &lt;chr&gt;, Planning.Region &lt;chr&gt;,\n#   Planning.Area &lt;chr&gt;\n\n\nShow the code\nrpm_processed &lt;- rpm_processed %&gt;%\n  rename(\n    `Project Name` = Project.Name,\n    `Transacted Price` = Transacted.Price....,\n    `Sale Date` = Sale.Date,\n    `Type of Sale` = Type.of.Sale,\n    `Type of Area` = Type.of.Area,\n    `Area SQM` = Area..SQM.,\n    `Unit Price PSM` = Unit.Price....PSM.,\n    `Property Type` = Property.Type,\n    `Completion Date` = Completion.Date,\n    `Purchaser Address Indicator` = Purchaser.Address.Indicator,\n    `Planning Region` = Planning.Region,\n    `Planning Area` = Planning.Area\n  )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-clean",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-clean",
    "title": "Take Home Exercise 1: Creating data visualisation beyond default",
    "section": "3.2 Data Clean",
    "text": "3.2 Data Clean\n\n3.2.1 Remove missing values\nCheck NA for all columns and remove them.\n\ncolSums(is.na(rpm_processed))\n\n               Project Name            Transacted Price \n                          0                           0 \n                  Sale Date                Type of Sale \n                          0                           0 \n               Type of Area                    Area SQM \n                          0                           0 \n             Unit Price PSM               Property Type \n                          0                           0 \n            Completion Date Purchaser Address Indicator \n                        682                           0 \n            Planning Region               Planning Area \n                          0                           0 \n\nrpm_cleaned &lt;- na.omit(rpm_processed)\n\n\n\n\n\n\n\nNote\n\n\n\nThere are a lot of missing value in column ‘Purchaser address indicator’. However, we will visualize this section as a separate series"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#basic-visualization",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#basic-visualization",
    "title": "Take Home Exercise 1: Creating data visualisation beyond default",
    "section": "3.3 Basic visualization",
    "text": "3.3 Basic visualization\n\n3.3.1 HDB and Private unit price trends\n\nPrivate unit price trendsHdb price trends\n\n\n\n\nShow the code\nprivate_data &lt;- rpm_cleaned %&gt;%\n  filter(`Purchaser Address Indicator` == \"Private\"&\n         `Sale Date` &gt;= as.Date(\"2024-01-01\") &\n         `Sale Date` &lt;= as.Date(\"2024-04-01\")) %&gt;%\n  group_by(`Sale Date`) %&gt;%\n  summarise(`Unit Price PSM` = mean(`Unit Price PSM`, na.rm = TRUE))\n\nggplot(private_data, aes(x = `Sale Date`, y = `Unit Price PSM`, group = 1)) +\n  geom_line() +\n  labs(title = \"Unit Price PSM Over Time for Private\",\n       x = \"Sale Date\",\n       y = \"Unit Price PSM\") +\n  theme_economist()\n\n\n\n\n\n\n\n\n\nShow the code\nhdb_data &lt;- rpm_cleaned %&gt;%\n  filter(`Purchaser Address Indicator` == \"HDB\"&\n         `Sale Date` &gt;= as.Date(\"2024-01-01\") &\n         `Sale Date` &lt;= as.Date(\"2024-04-01\")) %&gt;%\n  group_by(`Sale Date`) %&gt;%\n  summarise(`Unit Price PSM` = mean(`Unit Price PSM`, na.rm = TRUE))\n\nggplot(hdb_data, aes(x = `Sale Date`, y = `Unit Price PSM`, group = 1)) +\n  geom_line() +\n  labs(title = \"Unit Price PSM Over Time for HDB\",\n       x = \"Sale Date\",\n       y = \"Unit Price PSM\") +\n  theme_economist()\n\n\n\n\n\n\n\n\nFrom the plot above, we can see the unit prices of Hdb and Private are both between 15000 and 30000. We need to analyze based on the region to visualize the price trend better."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#price-trend-of-each-region",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#price-trend-of-each-region",
    "title": "Take Home Exercise 1: Creating data visualisation beyond default",
    "section": "4.1 Price trend of each region",
    "text": "4.1 Price trend of each region\n\nPlotCode\n\n\n\n\n\n\navg_price_by_region_monthly &lt;- rpm_cleaned %&gt;%\n  mutate(`Month` = floor_date(`Sale Date`, \"month\")) %&gt;%  \n  group_by(`Month`, `Planning Region`) %&gt;%\n  summarise(`Unit Price PSM` = mean(`Unit Price PSM`, na.rm = TRUE)) %&gt;%\n  ungroup() \n\nggplot(avg_price_by_region_monthly, aes(x = `Month`, y = `Unit Price PSM`, group = `Planning Region`, color = `Planning Region`)) +\n  geom_line() +\n  labs(title = \"Unit Price PSM Over Time by Planning Region\",\n       x = \"Month\",\n       y = \"Unit Price PSM\") +\n  theme_economist() +\n  theme(legend.position = \"bottom\",\n        legend.text = element_text(size = 6), \n        plot.title = element_text(size = 10)) \n\n\n\n\nFrom the plot above, we can see that the highest average unit price is Central Region. It’s not strange because Central Region is the most prosperous. However, the average price in areas other than the Central Region and East Region show an upward trend in 2023-2024."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#price-trends-by-type-of-sale",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#price-trends-by-type-of-sale",
    "title": "Take Home Exercise 1: Creating data visualisation beyond default",
    "section": "4.2 Price trends by type of sale",
    "text": "4.2 Price trends by type of sale\n\nPlotCode\n\n\n\n\n\n\nunitprice_typeofsale &lt;- rpm_cleaned %&gt;%\n  mutate(`Week` = floor_date(`Sale Date`, \"week\")) %&gt;%  \n  filter(`Week` &gt;= as.Date(\"2024-01-01\") & `Week` &lt; as.Date(\"2024-04-01\")) %&gt;%\n  group_by(`Week`, `Type of Sale`) %&gt;%\n  summarise(`Average Unit Price PSM` = mean(`Unit Price PSM`, na.rm = TRUE)) %&gt;%\n  ungroup() \n\ncompletedate_typeofsale &lt;- rpm_cleaned %&gt;%\n  mutate(`Week` = floor_date(`Sale Date`, \"week\")) %&gt;%  \n  filter(`Week` &gt;= as.Date(\"2024-01-01\") & `Week` &lt; as.Date(\"2024-04-01\")) %&gt;%\n  group_by(`Week`, `Type of Sale`) %&gt;%\n  summarise(`Average Completion Date` = mean(`Completion Date`, na.rm = TRUE)) %&gt;%\n  ungroup()\n\np1 &lt;- ggplot(unitprice_typeofsale, aes(x = `Week`, y = `Average Unit Price PSM`, group = `Type of Sale`, color = `Type of Sale`)) +\n  geom_line() +\n  labs(title = \"Average Unit Price PS by Type of Sale\",\n       x = \"Month\",\n       y = \"Average Unit Price PSM\") +\n  theme_minimal() +\n  theme(legend.position = \"left\",\n        legend.text = element_text(size = 6), \n        plot.title = element_text(size = 8))\n\np2 &lt;- ggplot(completedate_typeofsale, aes(x = `Week`, y = `Average Completion Date`, group = `Type of Sale`, color = `Type of Sale`)) +\n  geom_line() +\n  labs(title = \"Average Completion Date by Type of Sale\",\n       x = \"Month\",\n       y = \"Average Completion Date\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 8))\n\np1 &lt;- p1 + theme(legend.position = \"top\")\np2 &lt;- p2 + theme(legend.position = \"none\")\np1+p2\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nSet all uncompleted project date as 2030 to easier analysis.\n\n\n\nFrom the above plot, we can conclude that the price of New Sale in the first quarter of 2024 is higher than that of Sub Sale and Resale. This is because the houses in Resale are built earlier."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#price-trends-by-size",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#price-trends-by-size",
    "title": "Take Home Exercise 1: Creating data visualisation beyond default",
    "section": "4.3 Price trends by size",
    "text": "4.3 Price trends by size\n\n\nShow the code\nrpm_cleaned &lt;- rpm_cleaned %&gt;%\n  mutate(Area_Category = cut(`Area SQM`,\n                             breaks = c(-Inf, 100, 200, 300, 400, 500, Inf),\n                             labels = c(\"0-100\", \"100-200\", \"200-300\", \"300-400\", \"400-500\", \"&gt;500\")))\n\navg_price_by_area &lt;- rpm_cleaned %&gt;%\n  group_by(Area_Category) %&gt;%\n  summarise(Average_Unit_Price_PSM = mean(`Unit Price PSM`, na.rm = TRUE)) %&gt;%\n  ungroup()\n\nggplot(avg_price_by_area, aes(x = Area_Category, y = Average_Unit_Price_PSM, fill = Area_Category)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Average Unit Price PSM by Area SQM\",\n       x = \"Area (in m²)\",\n       y = \"Average Unit Price per m²\") +\n  theme_economist() +\n  theme(legend.position = \"none\") \n\n\n\n\n\nFrom the plot above, we can see the unit price of size between 300-400 m² is the lowest and size from 0 to 100 holds the highest unit price.\nNow, what if we visualize the unit price by size by region?\n\n\nShow the code\nrpm_cleaned &lt;- rpm_cleaned %&gt;%\n  mutate(`Area Category` = cut(`Area SQM`,\n                             breaks = c(-Inf, 100, 200, 300, 400, 500, Inf),\n                             labels = c(\"0-100\", \"100-200\", \"200-300\", \"300-400\", \"400-500\", \"&gt;500\")))\n\navg_price_by_area_region &lt;- rpm_cleaned %&gt;%\n  group_by(`Planning Region`, `Area Category`) %&gt;%\n  summarise(Average_Unit_Price_PSM = mean(`Unit Price PSM`, na.rm = TRUE)) %&gt;%\n  ungroup()\n\nggplot(avg_price_by_area_region, aes(x = `Area Category`, y = Average_Unit_Price_PSM, fill = `Area Category`)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  facet_wrap(~ `Planning Region`, scales = \"free_y\") +\n  labs(title = \"Average Unit Price PSM by Area SQM and Planning Region\",\n       x = \"Area SQM (in m²)\",\n       y = \"Average Unit Price per m²\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        axis.text.x = element_blank(),\n        strip.text.x = element_text(size = 8))\n\n\n\n\n\nAfter we separate the region, the price of each size shows a different trend. The price decreases when size increases in North East Region. But the unit price between 0-100 still remains the highest in all regions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take Home Exercise 2: Makeover",
    "section": "",
    "text": "The purpose of the makeover is to improve on the original visualization. Focus on what works, what doesn’t work, why those things don’t work, and how you made it better. You should try stick to the fields in the data set provided and improve upon the original visualization. However, if supplementing the data helps you tell a better story, go for it!\nIn this take-home exercise, you are required to:\n\nselect one data visualization from the Take-home Exercise 1 submission prepared by your classmate,\ncritic the submission in terms of clarity and aesthetics,\nprepare a sketch for the alternative design by using the data visualization design principles and best practices you had learned in Lesson 1 and 2.\nremake the original design by using ggplot2, ggplot2 extensions and tidyverse packages."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#loading-packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#loading-packages",
    "title": "Take Home Exercise 2: Makeover",
    "section": "2.1 Loading Packages",
    "text": "2.1 Loading Packages\nTo do this visualization makeover, we need these packages.\n\ntidyverse: an amalgamation of libraries for data handling (including ggplot2, dplyr, tidyr, readr, tibble)\nknitr: for creating dynamic html tables/reports\nggridges: extension of ggplot2 designed for plotting ridgeline plots\nggdist: extension of ggplot2 designed for visualising distribution and uncertainty,\ncolorspace: provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\nggrepel: provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: provides additional themes, geoms, and scales for ggplot package\nhrbrthemes: provides typography-centric themes and theme components for ggplot package\npatchwork: preparing composite figure created using ggplot package\nlubridate: for wrangling of date-time data\n\n\npacman::p_load(tidyverse, knitr, ggridges, ggdist, \n               colorspace, ggrepel, ggthemes, \n               hrbrthemes, patchwork, lubridate, plotly)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-preparation",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-preparation",
    "title": "Take Home Exercise 2: Makeover",
    "section": "2.2 Data Preparation",
    "text": "2.2 Data Preparation\n\nRealis24Q1 &lt;- read_csv('data/ResidentialTransaction20240414220633.csv')\n\nRealis_merged &lt;- read_csv('data/rpm.csv')\n\n\nglimpse(Realis24Q1)\n\nRows: 4,902\nColumns: 21\n$ `Project Name`                &lt;chr&gt; \"THE LANDMARK\", \"POLLEN COLLECTION\", \"SK…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2726888, 3850000, 2346000, 2190000, 1954…\n$ `Area (SQFT)`                 &lt;dbl&gt; 1076.40, 1808.35, 1087.16, 807.30, 796.5…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2533, 2129, 2158, 2713, 2453, 2577, 838,…\n$ `Sale Date`                   &lt;chr&gt; \"01 Jan 2024\", \"01 Jan 2024\", \"01 Jan 20…\n$ Address                       &lt;chr&gt; \"173 CHIN SWEE ROAD #22-11\", \"34 POLLEN …\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Land\", \"Strata\", \"Strata\", \"S…\n$ `Area (SQM)`                  &lt;dbl&gt; 100.0, 168.0, 101.0, 75.0, 74.0, 123.0, …\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 27269, 22917, 23228, 29200, 26405, 27741…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Terrace House\", \"Apartme…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 28/08/2020\", \"99 yrs from 0…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"Private\", \"N.A\", \"HDB\", \"N.A\", \"Private…\n$ `Postal Code`                 &lt;chr&gt; \"169878\", \"807233\", \"469657\", \"118992\", …\n$ `Postal District`             &lt;chr&gt; \"03\", \"28\", \"16\", \"05\", \"21\", \"21\", \"28\"…\n$ `Postal Sector`               &lt;chr&gt; \"16\", \"80\", \"46\", \"11\", \"59\", \"58\", \"79\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"North East Region\", \"…\n$ `Planning Area`               &lt;chr&gt; \"Outram\", \"Serangoon\", \"Bedok\", \"Queenst…\n\n\n\n#Convert \"-\" values with no characters before and after to NA\nRealis24Q1 &lt;- Realis24Q1 %&gt;%\n  mutate_all(~ ifelse(grepl(\"^-$\", .), NA, .))\n\n#Find the number of missing values for each col\ncolSums(is.na(Realis24Q1))\n\n               Project Name        Transacted Price ($) \n                          0                           0 \n                Area (SQFT)          Unit Price ($ PSF) \n                          0                           0 \n                  Sale Date                     Address \n                          0                           0 \n               Type of Sale                Type of Area \n                          0                           0 \n                 Area (SQM)          Unit Price ($ PSM) \n                          0                           0 \n              Nett Price($)               Property Type \n                       4896                           0 \n            Number of Units                      Tenure \n                          0                           0 \n            Completion Date Purchaser Address Indicator \n                        118                           0 \n                Postal Code             Postal District \n                          0                           0 \n              Postal Sector             Planning Region \n                          0                           0 \n              Planning Area \n                          0 \n\n\n\n#Convert \"-\" values with no characters before and after to NA\nRealis_merged &lt;- Realis_merged %&gt;%\n  mutate_all(~ ifelse(grepl(\"^-$\", .), NA, .))\n\n#Find the number of missing values for each col\ncolSums(is.na(Realis_merged))\n\n                       ...1                Project.Name \n                          0                           0 \n       Transacted.Price....                 Area..SQFT. \n                          0                           0 \n         Unit.Price....PSF.                   Sale.Date \n                          0                           0 \n                    Address                Type.of.Sale \n                          0                           0 \n               Type.of.Area                  Area..SQM. \n                          0                           0 \n         Unit.Price....PSM.               Nett.Price... \n                          0                       26770 \n              Property.Type             Number.of.Units \n                          0                           0 \n                     Tenure             Completion.Date \n                          0                         682 \nPurchaser.Address.Indicator                 Postal.Code \n                          0                           0 \n            Postal.District               Postal.Sector \n                          0                           0 \n            Planning.Region               Planning.Area \n                          0                           0 \n\n\n\n# For version control, start by defining new transformed datasets as copies of original dataset\nRealis24Q1_trfm &lt;- Realis24Q1\nRealis_merged_trfm &lt;- Realis_merged\n\n# Convert Sale date to date data type\nRealis24Q1_trfm$`Sale Date` &lt;- dmy(Realis24Q1$`Sale Date`)\nRealis_merged_trfm$`Sale Date` &lt;- dmy(Realis_merged$`Sale.Date`)\n\n# For Completion Date, (1) filter out missing values, (2) Calculate age of property caa 2024, (3) set Uncompleted as age 0\nRealis24Q1_trfm &lt;- Realis24Q1_trfm %&gt;% filter(!is.na(`Completion Date`))\nRealis_merged_trfm &lt;- Realis_merged_trfm %&gt;% filter(!is.na(`Completion.Date`))\nRealis24Q1_trfm$`Completion Date`[Realis24Q1_trfm$`Completion Date` == \"Uncompleted\"] &lt;- 2024\nRealis_merged_trfm$`Completion Date`[Realis_merged_trfm$`Completion.Date` == \"Uncompleted\"] &lt;- 2024\nRealis24Q1_trfm$Property_Age &lt;- 2024 - as.numeric(Realis24Q1_trfm$`Completion Date`)\nRealis_merged_trfm$Property_Age &lt;- 2024 - as.numeric(Realis_merged_trfm$`Completion.Date`)\n\n# For number of units, filter out the multiple-property transactions as outliers\nRealis24Q1_trfm &lt;- Realis24Q1_trfm %&gt;% filter(`Number of Units` &lt;= 1)\nRealis_merged_trfm &lt;- Realis_merged_trfm %&gt;% filter(`Number.of.Units` &lt;= 1)\n\n# For Tenure, bin values into Leasehold and 999yrs/Freehold\nRealis24Q1_trfm &lt;- Realis24Q1_trfm %&gt;%\n  mutate(Tenure = case_when(\n    grepl(\"^Freehold\", Tenure) ~ \"999yrs/Freehold\",\n    grepl(\"^9[0-9]{2}\", Tenure) ~ \"999yrs/Freehold\",\n    TRUE ~ \"Leasehold\"\n  ))\nRealis_merged_trfm &lt;- Realis_merged_trfm %&gt;%\n  mutate(Tenure = case_when(\n    grepl(\"^Freehold\", Tenure) ~ \"999yrs/Freehold\",\n    grepl(\"^9[0-9]{2}\", Tenure) ~ \"999yrs/Freehold\",\n    TRUE ~ \"Leasehold\"\n  ))\n\n# Review transformed dataset\nglimpse(Realis24Q1_trfm)\n\nRows: 4,783\nColumns: 22\n$ `Project Name`                &lt;chr&gt; \"THE LANDMARK\", \"POLLEN COLLECTION\", \"SK…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2726888, 3850000, 2346000, 2190000, 1954…\n$ `Area (SQFT)`                 &lt;dbl&gt; 1076.40, 1808.35, 1087.16, 807.30, 796.5…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2533, 2129, 2158, 2713, 2453, 2577, 838,…\n$ `Sale Date`                   &lt;date&gt; 2024-01-01, 2024-01-01, 2024-01-01, 202…\n$ Address                       &lt;chr&gt; \"173 CHIN SWEE ROAD #22-11\", \"34 POLLEN …\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Land\", \"Strata\", \"Strata\", \"S…\n$ `Area (SQM)`                  &lt;dbl&gt; 100.0, 168.0, 101.0, 75.0, 74.0, 123.0, …\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 27269, 22917, 23228, 29200, 26405, 27741…\n$ `Nett Price($)`               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Terrace House\", \"Apartme…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"Leasehold\", \"Leasehold\", \"Leasehold\", \"…\n$ `Completion Date`             &lt;chr&gt; \"2024\", \"2024\", \"2024\", \"2024\", \"2024\", …\n$ `Purchaser Address Indicator` &lt;chr&gt; \"Private\", \"N.A\", \"HDB\", \"N.A\", \"Private…\n$ `Postal Code`                 &lt;chr&gt; \"169878\", \"807233\", \"469657\", \"118992\", …\n$ `Postal District`             &lt;chr&gt; \"03\", \"28\", \"16\", \"05\", \"21\", \"21\", \"28\"…\n$ `Postal Sector`               &lt;chr&gt; \"16\", \"80\", \"46\", \"11\", \"59\", \"58\", \"79\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"North East Region\", \"…\n$ `Planning Area`               &lt;chr&gt; \"Outram\", \"Serangoon\", \"Bedok\", \"Queenst…\n$ Property_Age                  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 20, 11, 9, 11, 8, 8, 1…"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "pacman::p_load(ggrepel, patchwork, ggthemes, \n               tidyverse, ggridges, ggdist,\n               colorspace) \n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\nsummary(exam_data)\n\n      ID               CLASS              GENDER              RACE          \n Length:322         Length:322         Length:322         Length:322        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    ENGLISH          MATHS          SCIENCE     \n Min.   :21.00   Min.   : 9.00   Min.   :15.00  \n 1st Qu.:59.00   1st Qu.:58.00   1st Qu.:49.25  \n Median :70.00   Median :74.00   Median :65.00  \n Mean   :67.18   Mean   :69.33   Mean   :61.16  \n 3rd Qu.:78.00   3rd Qu.:85.00   3rd Qu.:74.75  \n Max.   :96.00   Max.   :99.00   Max.   :96.00  \n\n\n\n1 Histogram\nUsing the steps you have learned, build a histogram.\n\nggplot(data=exam_data, \n       aes(x = ENGLISH)) +\ngeom_histogram(bins=30,            \n                 color=\"black\",      \n                 fill=\"light blue\") \n\n\n\n\n\n\n2 Probability Density Plot\n\nggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_density(\n     color = \"#1696d2\",\n     adjust = .54,\n     alpha = .6\n  )\n\n\n\n\nThe alternative design. (Missing median_eng because the class abruptly ended.)\n\nmedian_eng &lt;- median(exam_data$ENGLISH)\nmean_eng &lt;- mean(exam_data$ENGLISH)\nstd_eng &lt;- (exam_data$ENGLISH)\n\nggplot(exam_data,\n       aes(x= ENGLISH)) +\n  geom_density(\n    color = \"#1696d2\",\n    adjust = .65,\n    alpha = .6) +\n  stat_function(\n    fun = dnorm, \n    args = list(mean = mean_eng,\n                sd = std_eng),\n    col = \"grey10\",\n    size = .8) +\n  \n  geom_vline(\n    aes(xintercept = mean_eng), \n    color=\"#4d5887\",\n    linewidth = .6,\n    linetype = \"dashed\") +\n  annotate(geom=\"text\", \n           x = mean_eng - 8,\n           y = 0.04, \n           label = paste0(\"Mean ENGLISH: \",round((mean_eng),2)),\n           color = \"#4d5887\") \n\n\n\n\n\n\n3 Visualising Distribution with Ridgeline Plot\n\nggplot(exam_data, aes(x = ENGLISH, y = fct_relevel(CLASS, rev(unique(CLASS))))) +\n  geom_density_ridges() +\n  scale_y_discrete(labels = rev) + # This is to ensure the order of classes is from top to bottom\n  labs(title = \"Distribution of English Scores by Class\",\n       x = \"English Score\",\n       y = \"Class\") +\n  theme_ridges(grid = FALSE) \n\n\n\n\n\nridgeline1 &lt;- ggplot(exam_data, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\nridgeline2 &lt;- ggplot(exam_data, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\nridgeline3 &lt;- ggplot(exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\nridgeline4 &lt;- ggplot(exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\n\nprint(ridgeline1)\n\n\n\nprint(ridgeline2) \n\n\n\nprint(ridgeline3) \n\n\n\nprint(ridgeline4)\n\n\n\n\n\n\n4 Rainploud Plot\n\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take Home Exercise 3: Learning Behavior Patterns Analysis",
    "section": "",
    "text": "show the code\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(lubridate)\nlibrary(cluster)\nlibrary(factoextra)\nlibrary(fmsb)\nlibrary(reshape2)\nlibrary(networkD3)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-clean",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-clean",
    "title": "Take Home Exercise 3: Learning Behavior Patterns Analysis",
    "section": "2.2 Data Clean",
    "text": "2.2 Data Clean\n\n2.2.1 Missing Value\nFirst, we check if there is missing value in these 3 data sets.\n\n\nshow the code\nmissing_values1 &lt;- colSums(is.na(stu_info))\nprint(missing_values1)\n\n\n     index student_ID        sex        age      major \n         0          0          0          0          0 \n\n\nshow the code\nmissing_values2 &lt;- colSums(is.na(tit_info))\nprint(missing_values2)\n\n\n        index      title_ID         score     knowledge sub_knowledge \n            0             0             0             0             0 \n\n\nshow the code\nmissing_values3 &lt;- colSums(is.na(sub_info))\nprint(missing_values3)\n\n\n      index       class        time       state       score    title_ID \n          0           0           0           0           0           0 \n     method      memory timeconsume  student_ID \n          0           0           0           0 \n\n\n\n\n2.2.2 Outliers\nThere is no missing value in all 3 data sets. Now we see if there are outliers. :\n\nstateclasstime consume\n\n\n\n\nshow the code\nunique_state &lt;- unique(sub_info$state)\nprint(unique_state)\n\n\n [1] \"Absolutely_Correct\" \"Error1\"             \"Absolutely_Error\"  \n [4] \"Error6\"             \"Error4\"             \"Partially_Correct\" \n [7] \"Error2\"             \"Error3\"             \"Error5\"            \n[10] \"Error7\"             \"Error8\"             \"Error9\"            \n[13] \"�������\"           \n\n\n\n\n\n\nshow the code\nunique_class &lt;- unique(sub_info$class)\nprint(unique_class)\n\n\n [1] \"Class1\"  \"class\"   \"Class2\"  \"Class3\"  \"Class4\"  \"Class5\"  \"Class6\" \n [8] \"Class7\"  \"Class8\"  \"Class9\"  \"Class10\" \"Class11\" \"Class12\" \"Class13\"\n[15] \"Class14\" \"Class15\"\n\n\n\n\n\n\nshow the code\nunique_timeconsume &lt;- unique(sub_info$timeconsume) \nprint(unique_timeconsume)\n\n\n  [1] \"3\"   \"2\"   \"5\"   \"4\"   \"1\"   \"9\"   \"6\"   \"--\"  \"18\"  \"61\"  \"7\"   \"59\" \n [13] \"10\"  \"8\"   \"12\"  \"13\"  \"16\"  \"15\"  \"183\" \"68\"  \"314\" \"64\"  \"60\"  \"11\" \n [25] \"96\"  \"94\"  \"58\"  \"67\"  \"54\"  \"17\"  \"122\" \"19\"  \"126\" \"14\"  \"91\"  \"50\" \n [37] \"21\"  \"40\"  \"23\"  \"20\"  \"80\"  \"31\"  \"118\" \"25\"  \"26\"  \"29\"  \"28\"  \"27\" \n [49] \"24\"  \"65\"  \"135\" \"63\"  \"103\" \"114\" \"258\" \"254\" \"85\"  \"66\"  \"69\"  \"90\" \n [61] \"132\" \"173\" \"48\"  \"34\"  \"272\" \"38\"  \"113\" \"116\" \"32\"  \"76\"  \"22\"  \"190\"\n [73] \"187\" \"73\"  \"215\" \"123\" \"246\" \"146\" \"57\"  \"89\"  \"88\"  \"30\"  \"245\" \"75\" \n [85] \"285\" \"70\"  \"400\" \"205\" \"36\"  \"164\" \"163\" \"162\" \"165\" \"266\" \"62\"  \"172\"\n [97] \"143\" \"184\" \"42\"  \"377\" \"160\" \"33\"  \"35\"  \"159\" \"182\" \"41\"  \"52\"  \"74\" \n[109] \"72\"  \"46\"  \"264\" \"81\"  \"153\" \"83\"  \"82\"  \"39\"  \"37\"  \"56\"  \"-\"   \"115\"\n[121] \"55\"  \"286\" \"275\" \"331\" \"280\" \"274\" \"269\" \"288\" \"271\" \"136\" \"117\" \"276\"\n[133] \"277\" \"356\" \"79\"  \"147\" \"44\"  \"350\" \"394\" \"45\"  \"315\" \"321\" \"302\" \"152\"\n[145] \"309\" \"47\"  \"53\"  \"51\"  \"307\" \"201\" \"43\"  \"109\" \"326\" \"49\"  \"77\"  \"71\" \n[157] \"385\" \"78\"  \"220\" \"217\" \"86\"  \"134\" \"84\"  \"106\" \"166\" \"124\" \"373\" \"289\"\n\n\n\n\n\nFor outliers “�������” , simply remove it.\n\nvalid_states &lt;- c(\"Absolutely_Correct\", \"Absolutely_Error\", \"Error1\", \"Error2\", \"Error3\", \"Error4\", \"Error6\", \"Error7\", \"Error8\", \"Error9\", \"Partially_Correct\")\n\n# 过滤数据，只保留 state 列中包含指定值的行\nsub_info &lt;- sub_info %&gt;%\n  filter(state %in% valid_states)\nunique(sub_info$state)\n\n [1] \"Absolutely_Correct\" \"Error1\"             \"Absolutely_Error\"  \n [4] \"Error6\"             \"Error4\"             \"Partially_Correct\" \n [7] \"Error2\"             \"Error3\"             \"Error7\"            \n[10] \"Error8\"             \"Error9\"            \n\n\nFor outliers “class” , replace with the highest frequency of the corresponding student_ID.\n\nreplace_class &lt;- function(df) {\n  df$class &lt;- as.character(df$class)\n  \n  class_indices &lt;- which(df$class == 'class')\n  \n  for (index in class_indices) {\n    student_id &lt;- df$student_ID[index]\n    student_classes &lt;- df$class[df$student_ID == student_id & df$class != 'class']\n    class_counts &lt;- table(student_classes)\n    \n    if (length(class_counts) &gt; 0) {\n      most_common_class &lt;- names(which.max(class_counts))\n      df$class[index] &lt;- most_common_class\n    }\n  }\n  \n  return(df)\n}\nsub_info &lt;- replace_class(sub_info)\nunique(sub_info$class)\n\n [1] \"Class1\"  \"Class2\"  \"Class3\"  \"Class4\"  \"Class5\"  \"Class6\"  \"Class7\" \n [8] \"Class8\"  \"Class9\"  \"Class10\" \"Class11\" \"Class12\" \"Class13\" \"Class14\"\n[15] \"Class15\"\n\n\nFor outliers ‘-’ and ‘–’, remove the corresponding rows.\n\nsub_info &lt;- sub_info %&gt;%\n  filter(!(timeconsume %in% c('-', '--')))\nunique(sub_info$timeconsume)\n\n  [1] \"3\"   \"2\"   \"5\"   \"4\"   \"1\"   \"9\"   \"6\"   \"18\"  \"61\"  \"7\"   \"59\"  \"10\" \n [13] \"8\"   \"12\"  \"13\"  \"16\"  \"15\"  \"183\" \"68\"  \"314\" \"64\"  \"60\"  \"11\"  \"96\" \n [25] \"94\"  \"58\"  \"67\"  \"54\"  \"17\"  \"122\" \"19\"  \"126\" \"14\"  \"91\"  \"50\"  \"21\" \n [37] \"40\"  \"23\"  \"20\"  \"80\"  \"31\"  \"118\" \"25\"  \"26\"  \"29\"  \"28\"  \"27\"  \"24\" \n [49] \"65\"  \"135\" \"63\"  \"103\" \"114\" \"258\" \"254\" \"85\"  \"66\"  \"69\"  \"90\"  \"132\"\n [61] \"173\" \"48\"  \"34\"  \"272\" \"38\"  \"113\" \"116\" \"32\"  \"76\"  \"22\"  \"190\" \"187\"\n [73] \"73\"  \"215\" \"123\" \"246\" \"146\" \"57\"  \"89\"  \"88\"  \"30\"  \"245\" \"75\"  \"285\"\n [85] \"70\"  \"400\" \"205\" \"36\"  \"164\" \"163\" \"162\" \"165\" \"266\" \"62\"  \"172\" \"143\"\n [97] \"184\" \"42\"  \"377\" \"160\" \"33\"  \"35\"  \"159\" \"182\" \"41\"  \"52\"  \"74\"  \"72\" \n[109] \"46\"  \"264\" \"81\"  \"153\" \"83\"  \"82\"  \"39\"  \"37\"  \"56\"  \"115\" \"55\"  \"286\"\n[121] \"275\" \"331\" \"280\" \"274\" \"269\" \"288\" \"271\" \"136\" \"117\" \"276\" \"277\" \"79\" \n[133] \"147\" \"44\"  \"350\" \"394\" \"45\"  \"315\" \"321\" \"302\" \"152\" \"47\"  \"53\"  \"51\" \n[145] \"307\" \"201\" \"43\"  \"109\" \"326\" \"49\"  \"77\"  \"71\"  \"385\" \"78\"  \"220\" \"217\"\n[157] \"86\"  \"134\" \"84\"  \"106\" \"166\" \"124\" \"373\" \"289\"\n\n\nSave the dataset and name it ‘sub_info.csv’\n\nwrite.csv(sub_info, 'data/sub_info.csv', row.names = FALSE)\nhead(sub_info)\n\n  index  class       time              state score\n1     0 Class1 1704209872 Absolutely_Correct     3\n2     1 Class1 1704209852 Absolutely_Correct     3\n3     2 Class1 1704209838 Absolutely_Correct     3\n4     3 Class1 1704208923 Absolutely_Correct     3\n5     4 Class1 1704208359 Absolutely_Correct     4\n6     5 Class1 1704208330             Error1     0\n                       title_ID                      method memory timeconsume\n1 Question_bumGRTJ0c8p4v5D6eHZa Method_Cj9Ya2R7fZd6xs1q5mNQ    320           3\n2 Question_62XbhBvJ8NUSnApgDL94 Method_gj1NLb4Jn7URf9K2kQPd    356           3\n3 Question_ZTbD7mxr2OUp8Fz6iNjy Method_5Q4KoXthUuYz3bvrTDFm    196           2\n4 Question_xqlJkmRaP0otZcX4fK3W Method_m8vwGkEZc3TSW2xqYUoR    308           2\n5 Question_FNg8X9v5zcbB1tQrxHR3 Method_Cj9Ya2R7fZd6xs1q5mNQ    320           3\n6 Question_FNg8X9v5zcbB1tQrxHR3 Method_gj1NLb4Jn7URf9K2kQPd      0           5\n            student_ID\n1 8b6d1125760bd3939b6e\n2 8b6d1125760bd3939b6e\n3 8b6d1125760bd3939b6e\n4 63eef37311aaac915a45\n5 5d89810b20079366fcc2\n6 5d89810b20079366fcc2\n\n\n\n\n2.2.3 Convert datetime\nThe time span is from August 31, 2023 to January 25, 2024, a total of 148 days. However, the content in column ‘time’ is actually in seconds. So we need to convert to datetime.\n\nsub_info &lt;- sub_info %&gt;%\n  mutate(day = wday(as.POSIXct(time, origin = \"1970-01-01\", tz = \"UTC\"), week_start = 1))\nunique(sub_info$day)\n\n[1] 2 1 6 5 4 7 3\n\n\n\n\n2.2.4 Match the unique title_ID with unique knowledge\nFrom the code below we can see some titles match multiple knowledge\n\ntitle_knowledge_check &lt;- tit_info %&gt;%\n  group_by(title_ID) %&gt;%\n  summarise(knowledge_count = n_distinct(knowledge)) %&gt;%\n  filter(knowledge_count &gt; 1)\n\nprint(title_knowledge_check)\n\n# A tibble: 5 × 2\n  title_ID                      knowledge_count\n  &lt;chr&gt;                                   &lt;int&gt;\n1 Question_QRm48lXxzdP7Tn1WgNOf               2\n2 Question_lU2wvHSZq7m43xiVroBc               2\n3 Question_oCjnFLbIs4Uxwek9rBpu               2\n4 Question_pVKXjZn0BkSwYcsa7C31               2\n5 Question_x2Fy7rZ3SwYl9jMQkpOD               2\n\n\nSince we don’t know when the students submit the questions, which knowledge they actually focus on, so we use the probability to match the knowledge.\n\ntitle_knowledge_count &lt;- tit_info %&gt;%\n  group_by(title_ID) %&gt;%\n  summarise(knowledge_list = list(unique(knowledge))) %&gt;%\n  mutate(knowledge = sapply(knowledge_list, function(x) ifelse(length(x) &gt; 0, x[1], NA)),\n         knowledge1 = sapply(knowledge_list, function(x) ifelse(length(x) &gt; 1, x[2], NA))) %&gt;%\n  select(-knowledge_list)\n\n# 合并知识信息到sub_info\nset.seed(123) # 确保结果可重复\nsub_info &lt;- sub_info %&gt;%\n  left_join(title_knowledge_count, by = \"title_ID\") %&gt;%\n  rowwise() %&gt;%\n  mutate(knowledge = ifelse(!is.na(knowledge1), \n                            sample(c(knowledge, knowledge1), 1), \n                            knowledge)) %&gt;%\n  ungroup() %&gt;%\n  select(-knowledge1)\n\n# 查看处理后的数据框前几行\nhead(sub_info)\n\n# A tibble: 6 × 12\n  index class     time state score title_ID method memory timeconsume student_ID\n  &lt;int&gt; &lt;chr&gt;    &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;     \n1     0 Class1  1.70e9 Abso…     3 Questio… Metho…    320 3           8b6d11257…\n2     1 Class1  1.70e9 Abso…     3 Questio… Metho…    356 3           8b6d11257…\n3     2 Class1  1.70e9 Abso…     3 Questio… Metho…    196 2           8b6d11257…\n4     3 Class1  1.70e9 Abso…     3 Questio… Metho…    308 2           63eef3731…\n5     4 Class1  1.70e9 Abso…     4 Questio… Metho…    320 3           5d89810b2…\n6     5 Class1  1.70e9 Erro…     0 Questio… Metho…      0 5           5d89810b2…\n# ℹ 2 more variables: day &lt;dbl&gt;, knowledge &lt;chr&gt;\n\n\nFinally, we need to calculate the average answering correct rate and average consuming time for each student.\n\nsub_info &lt;- sub_info %&gt;%\n  left_join(tit_info %&gt;% select(title_ID, score), by = \"title_ID\")\nsub_info &lt;- sub_info %&gt;%\n  mutate(rate = score.x / score.y) %&gt;%\n  select(-score.x, -score.y)\n\nhead(sub_info)\n\n# A tibble: 6 × 12\n  index class     time state title_ID method memory timeconsume student_ID   day\n  &lt;int&gt; &lt;chr&gt;    &lt;int&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt;\n1     0 Class1  1.70e9 Abso… Questio… Metho…    320 3           8b6d11257…     2\n2     1 Class1  1.70e9 Abso… Questio… Metho…    356 3           8b6d11257…     2\n3     2 Class1  1.70e9 Abso… Questio… Metho…    196 2           8b6d11257…     2\n4     3 Class1  1.70e9 Abso… Questio… Metho…    308 2           63eef3731…     2\n5     4 Class1  1.70e9 Abso… Questio… Metho…    320 3           5d89810b2…     2\n6     5 Class1  1.70e9 Erro… Questio… Metho…      0 5           5d89810b2…     2\n# ℹ 2 more variables: knowledge &lt;chr&gt;, rate &lt;dbl&gt;\n\nwrite.csv(sub_info,'data/sub_info.csv',row.names = FALSE)\n\n\n\n2.2.5 Final data\nNow we merged with student information and rearrange the column for the further analysis.\n\n# 计算每个学生的平均rate\navg_rate &lt;- sub_info %&gt;%\n  group_by(student_ID) %&gt;%\n  summarise(average_rate = mean(rate, na.rm = TRUE))\n\n# 计算每个学生每种knowledge的百分比\nknowledge_percentage &lt;- sub_info %&gt;%\n  group_by(student_ID, knowledge) %&gt;%\n  summarise(counts = n()) %&gt;%\n  ungroup() %&gt;%\n  group_by(student_ID) %&gt;%\n  mutate(total_counts = sum(counts),\n         percentage = counts / total_counts) %&gt;%\n  select(student_ID, knowledge, percentage) %&gt;%\n  spread(key = knowledge, value = percentage, fill = 0)\n\n# 合并学生信息和计算结果\nfinal_data &lt;- stu_info %&gt;%\n  select(-index) %&gt;%\n  left_join(avg_rate, by = \"student_ID\") %&gt;%\n  left_join(sub_info %&gt;% select(student_ID, day) %&gt;% distinct(), by = \"student_ID\") %&gt;%\n  left_join(knowledge_percentage, by = \"student_ID\")\n\n# 查看结果\nhead(final_data)\n\n            student_ID    sex age  major average_rate day      b3C9s      g7R2j\n1 8b6d1125760bd3939b6e female  24 J23517    0.5187266   2 0.07865169 0.06741573\n2 8b6d1125760bd3939b6e female  24 J23517    0.5187266   3 0.07865169 0.06741573\n3 8b6d1125760bd3939b6e female  24 J23517    0.5187266   4 0.07865169 0.06741573\n4 63eef37311aaac915a45 female  21 J87654    0.1597715   2 0.01654846 0.05437352\n5 63eef37311aaac915a45 female  21 J87654    0.1597715   7 0.01654846 0.05437352\n6 63eef37311aaac915a45 female  21 J87654    0.1597715   4 0.01654846 0.05437352\n       k4W1c     m3D1v      r8S3g      s8Y2f     t5V9e     y9W5d\n1 0.02247191 0.2247191 0.32584270 0.02247191 0.1011236 0.1573034\n2 0.02247191 0.2247191 0.32584270 0.02247191 0.1011236 0.1573034\n3 0.02247191 0.2247191 0.32584270 0.02247191 0.1011236 0.1573034\n4 0.00000000 0.4018913 0.07801418 0.05673759 0.1229314 0.2695035\n5 0.00000000 0.4018913 0.07801418 0.05673759 0.1229314 0.2695035\n6 0.00000000 0.4018913 0.07801418 0.05673759 0.1229314 0.2695035\n\nwrite.csv(final_data,'data/final_data.csv')"
  }
]